{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/megapose6d/megapose6d.git\n",
        "%cd megapose6d\n",
        "!git submodule update --init\n",
        "\n",
        "# Install megapose using pip directly\n",
        "!pip install -e.\n",
        "\n",
        "# Modify the scripts to use sys.executable instead of CONDA_PREFIX\n",
        "import sys\n",
        "import fileinput\n",
        "\n",
        "scripts_to_modify = [\n",
        "    'src/megapose/scripts/download.py',\n",
        "    'src/megapose/scripts/run_inference_on_example.py',\n",
        "    'src/megapose/config.py' # Modify config.py as well\n",
        "]\n",
        "\n",
        "for script_path in scripts_to_modify:\n",
        "    with fileinput.FileInput(script_path, inplace=True, backup='') as file:\n",
        "        for line in file:\n",
        "            if script_path == 'src/megapose/config.py' and 'PYTHON_BIN_PATH = Path(sys.executable)' in line:\n",
        "                print('import sys')\n",
        "                print(line, end='')\n",
        "            # Replace the line that uses os.environ[\"CONDA_PREFIX\"]\n",
        "            elif 'PYTHON_BIN_PATH = Path(os.environ[\"CONDA_PREFIX\"])' in line:\n",
        "                print('PYTHON_BIN_PATH = Path(sys.executable)')\n",
        "            else:\n",
        "                print(line, end='')\n",
        "\n",
        "print(\"Hello\")\n",
        "!python -m megapose.scripts.download --megapose_models\n",
        "!python -m megapose.scripts.run_inference_on_example barbecue-sauce --run-inference"
      ],
      "metadata": {
        "outputId": "6bc70393-ea12-4a69-b417-c1401ffe6bfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IQ7ov742MBv"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'megapose6d'...\n",
            "remote: Enumerating objects: 205, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 205 (delta 23), reused 14 (delta 14), pack-reused 146 (from 2)\u001b[K\n",
            "Receiving objects: 100% (205/205), 19.55 MiB | 15.64 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n",
            "/content/megapose6d/megapose6d\n",
            "Submodule 'deps/bop_toolkit_challenge' (https://github.com/ylabbe/bop_toolkit_challenge) registered for path 'deps/bop_toolkit_challenge'\n",
            "Cloning into '/content/megapose6d/megapose6d/deps/bop_toolkit_challenge'...\n",
            "Submodule path 'deps/bop_toolkit_challenge': checked out '55f3bf1f70d7a85e846e747cde19633117bfe0df'\n",
            "Obtaining file:///content/megapose6d/megapose6d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools_scm>=6.4.2 in /usr/local/lib/python3.12/dist-packages (from megapose==1.0) (9.2.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from setuptools_scm>=6.4.2->megapose==1.0) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from setuptools_scm>=6.4.2->megapose==1.0) (75.2.0)\n",
            "Building wheels for collected packages: megapose\n",
            "  Building editable for megapose (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for megapose: filename=megapose-1.0-0.editable-py3-none-any.whl size=7830 sha256=82ee286d9d13ef2ce215b6f16bc205573c55527c76abb48eef647418cfd55adb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ena46fa5/wheels/d1/3c/ef/50205f3e381d1e052fb1bca31d15bc15047565f7b1b96a9a5c\n",
            "Successfully built megapose\n",
            "Installing collected packages: megapose\n",
            "  Attempting uninstall: megapose\n",
            "    Found existing installation: megapose 1.0\n",
            "    Uninstalling megapose-1.0:\n",
            "      Successfully uninstalled megapose-1.0\n",
            "Successfully installed megapose-1.0\n",
            "Hello\n",
            "MKL_NUM_THREADS: 1\n",
            "OMP_NUM_THREADS: 1\n",
            "CUDA_VISIBLE_DEVICES: 0\n",
            "EGL_VISIBLE_DEVICES: 0\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/megapose6d/megapose6d/src/megapose/scripts/download.py\", line 25, in <module>\n",
            "    from megapose.config import LOCAL_DATA_DIR, PROJECT_DIR\n",
            "  File \"/content/megapose6d/megapose6d/src/megapose/config.py\", line 45, in <module>\n",
            "    PYTHON_BIN_PATH = Path(sys.executable)\n",
            "                           ^^^\n",
            "NameError: name 'sys' is not defined. Did you forget to import 'sys'?\n",
            "MKL_NUM_THREADS: 1\n",
            "OMP_NUM_THREADS: 1\n",
            "CUDA_VISIBLE_DEVICES: 0\n",
            "EGL_VISIBLE_DEVICES: 0\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/megapose6d/megapose6d/src/megapose/scripts/run_inference_on_example.py\", line 15, in <module>\n",
            "    from megapose.config import LOCAL_DATA_DIR\n",
            "  File \"/content/megapose6d/megapose6d/src/megapose/config.py\", line 45, in <module>\n",
            "    PYTHON_BIN_PATH = Path(sys.executable)\n",
            "                           ^^^\n",
            "NameError: name 'sys' is not defined. Did you forget to import 'sys'?\n"
          ]
        }
      ],
      "id": "6IQ7ov742MBv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3069329b",
        "outputId": "e8694ac7-68b1-4368-c1a0-37f97d2ebbff"
      },
      "source": [
        "!ls -R /content/megapose6d/"
      ],
      "id": "3069329b",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/megapose6d/:\n",
            "CLA    docker\tlicense_files  notebooks       README.md  src\n",
            "conda  images\tlocal_data     pyproject.toml  setup.cfg\n",
            "deps   LICENSE\tmegapose6d     rclone.conf     setup.py\n",
            "\n",
            "/content/megapose6d/conda:\n",
            "environment_full.yaml  environment.yaml\n",
            "\n",
            "/content/megapose6d/deps:\n",
            "bop_toolkit_challenge\n",
            "\n",
            "/content/megapose6d/deps/bop_toolkit_challenge:\n",
            "bop_toolkit_lib  docs  LICENSE\tREADME.md  requirements.txt  scripts  setup.py\n",
            "\n",
            "/content/megapose6d/deps/bop_toolkit_challenge/bop_toolkit_lib:\n",
            "colors.json\t\t     inout.py\t       renderer_py.py\n",
            "config.py\t\t     misc.py\t       score.py\n",
            "dataset_params.py\t     pose_error.py     transform.py\n",
            "droid_sans_mono_license.txt  pose_matching.py  view_sampler.py\n",
            "droid_sans_mono.ttf\t     renderer_cpp.py   visibility.py\n",
            "__init__.py\t\t     renderer.py       visualization.py\n",
            "\n",
            "/content/megapose6d/deps/bop_toolkit_challenge/docs:\n",
            "bop_challenge_2019_re-evaluation_27-01-2020.md\tbop_datasets_format.md\n",
            "\n",
            "/content/megapose6d/deps/bop_toolkit_challenge/scripts:\n",
            "calc_gt_distribution.py  check_results_bop19.py     render_train_imgs.py\n",
            "calc_gt_info_custom.py\t eval_bop19_dummy.py\t    show_performance_bop19.py\n",
            "calc_gt_info_multi.py\t eval_bop19.py\t\t    vis_est_poses.py\n",
            "calc_gt_info.py\t\t eval_calc_errors.py\t    vis_gt_poses.py\n",
            "calc_gt_masks.py\t eval_calc_scores.py\t    vis_object_symmetries.py\n",
            "calc_masks_custom.py\t meshlab_scripts\n",
            "calc_model_info.py\t remesh_models_for_eval.py\n",
            "\n",
            "/content/megapose6d/deps/bop_toolkit_challenge/scripts/meshlab_scripts:\n",
            "'remesh_for_eval_cell=0.25.mlx'  'remesh_for_eval_cell=0.5.mlx'\n",
            "\n",
            "/content/megapose6d/docker:\n",
            "Dockerfile.megapose\n",
            "\n",
            "/content/megapose6d/images:\n",
            "dataset.jpg\t       dataset_renders.png  pose-estimation.jpg\n",
            "dataset_renders_2.png  example\t\t    pose-estimation.png\n",
            "\n",
            "/content/megapose6d/images/example:\n",
            "all_results.png  contour_overlay.png  detections.png  mesh_overlay.png\n",
            "\n",
            "/content/megapose6d/license_files:\n",
            "python_license_header.txt\n",
            "\n",
            "/content/megapose6d/local_data:\n",
            "\n",
            "/content/megapose6d/megapose6d:\n",
            "CLA    docker\tlicense_files  notebooks       README.md  src\n",
            "conda  images\tlocal_data     pyproject.toml  setup.cfg\n",
            "deps   LICENSE\tmegapose6d     rclone.conf     setup.py\n",
            "\n",
            "/content/megapose6d/megapose6d/conda:\n",
            "environment_full.yaml  environment.yaml\n",
            "\n",
            "/content/megapose6d/megapose6d/deps:\n",
            "bop_toolkit_challenge\n",
            "\n",
            "/content/megapose6d/megapose6d/deps/bop_toolkit_challenge:\n",
            "bop_toolkit_lib  docs  LICENSE\tREADME.md  requirements.txt  scripts  setup.py\n",
            "\n",
            "/content/megapose6d/megapose6d/deps/bop_toolkit_challenge/bop_toolkit_lib:\n",
            "colors.json\t\t     inout.py\t       renderer_py.py\n",
            "config.py\t\t     misc.py\t       score.py\n",
            "dataset_params.py\t     pose_error.py     transform.py\n",
            "droid_sans_mono_license.txt  pose_matching.py  view_sampler.py\n",
            "droid_sans_mono.ttf\t     renderer_cpp.py   visibility.py\n",
            "__init__.py\t\t     renderer.py       visualization.py\n",
            "\n",
            "/content/megapose6d/megapose6d/deps/bop_toolkit_challenge/docs:\n",
            "bop_challenge_2019_re-evaluation_27-01-2020.md\tbop_datasets_format.md\n",
            "\n",
            "/content/megapose6d/megapose6d/deps/bop_toolkit_challenge/scripts:\n",
            "calc_gt_distribution.py  check_results_bop19.py     render_train_imgs.py\n",
            "calc_gt_info_custom.py\t eval_bop19_dummy.py\t    show_performance_bop19.py\n",
            "calc_gt_info_multi.py\t eval_bop19.py\t\t    vis_est_poses.py\n",
            "calc_gt_info.py\t\t eval_calc_errors.py\t    vis_gt_poses.py\n",
            "calc_gt_masks.py\t eval_calc_scores.py\t    vis_object_symmetries.py\n",
            "calc_masks_custom.py\t meshlab_scripts\n",
            "calc_model_info.py\t remesh_models_for_eval.py\n",
            "\n",
            "/content/megapose6d/megapose6d/deps/bop_toolkit_challenge/scripts/meshlab_scripts:\n",
            "'remesh_for_eval_cell=0.25.mlx'  'remesh_for_eval_cell=0.5.mlx'\n",
            "\n",
            "/content/megapose6d/megapose6d/docker:\n",
            "Dockerfile.megapose\n",
            "\n",
            "/content/megapose6d/megapose6d/images:\n",
            "dataset.jpg\t       dataset_renders.png  pose-estimation.jpg\n",
            "dataset_renders_2.png  example\t\t    pose-estimation.png\n",
            "\n",
            "/content/megapose6d/megapose6d/images/example:\n",
            "all_results.png  contour_overlay.png  detections.png  mesh_overlay.png\n",
            "\n",
            "/content/megapose6d/megapose6d/license_files:\n",
            "python_license_header.txt\n",
            "\n",
            "/content/megapose6d/megapose6d/local_data:\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d:\n",
            "CLA    docker\tlicense_files  pyproject.toml  setup.cfg\n",
            "conda  images\tlocal_data     rclone.conf     setup.py\n",
            "deps   LICENSE\tnotebooks      README.md       src\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/conda:\n",
            "environment_full.yaml  environment.yaml\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/deps:\n",
            "bop_toolkit_challenge\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/deps/bop_toolkit_challenge:\n",
            "bop_toolkit_lib  docs  LICENSE\tREADME.md  requirements.txt  scripts  setup.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/deps/bop_toolkit_challenge/bop_toolkit_lib:\n",
            "colors.json\t\t     inout.py\t       renderer_py.py\n",
            "config.py\t\t     misc.py\t       score.py\n",
            "dataset_params.py\t     pose_error.py     transform.py\n",
            "droid_sans_mono_license.txt  pose_matching.py  view_sampler.py\n",
            "droid_sans_mono.ttf\t     renderer_cpp.py   visibility.py\n",
            "__init__.py\t\t     renderer.py       visualization.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/deps/bop_toolkit_challenge/docs:\n",
            "bop_challenge_2019_re-evaluation_27-01-2020.md\tbop_datasets_format.md\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/deps/bop_toolkit_challenge/scripts:\n",
            "calc_gt_distribution.py  check_results_bop19.py     render_train_imgs.py\n",
            "calc_gt_info_custom.py\t eval_bop19_dummy.py\t    show_performance_bop19.py\n",
            "calc_gt_info_multi.py\t eval_bop19.py\t\t    vis_est_poses.py\n",
            "calc_gt_info.py\t\t eval_calc_errors.py\t    vis_gt_poses.py\n",
            "calc_gt_masks.py\t eval_calc_scores.py\t    vis_object_symmetries.py\n",
            "calc_masks_custom.py\t meshlab_scripts\n",
            "calc_model_info.py\t remesh_models_for_eval.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/deps/bop_toolkit_challenge/scripts/meshlab_scripts:\n",
            "'remesh_for_eval_cell=0.25.mlx'  'remesh_for_eval_cell=0.5.mlx'\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/docker:\n",
            "Dockerfile.megapose\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/images:\n",
            "dataset.jpg\t       dataset_renders.png  pose-estimation.jpg\n",
            "dataset_renders_2.png  example\t\t    pose-estimation.png\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/images/example:\n",
            "all_results.png  contour_overlay.png  detections.png  mesh_overlay.png\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/license_files:\n",
            "python_license_header.txt\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/local_data:\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/notebooks:\n",
            "megapose_custom_model.ipynb\t\trender_megapose_dataset.ipynb\n",
            "megapose_estimator_visualization.ipynb\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src:\n",
            "megapose  megapose.egg-info\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose:\n",
            "bop_config.py  datasets    __init__.py\tpanda3d_renderer  training\n",
            "config.py      evaluation  lib3d\tscripts\t\t  utils\n",
            "data\t       inference   models\ttests\t\t  visualization\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/data:\n",
            "data_4608.qua  data_512.qua  data_576.qua  data_72.qua\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/datasets:\n",
            "augmentations.py\t__init__.py\t\t    scene_dataset.py\n",
            "bop_object_datasets.py\tmodelnet_object_dataset.py  scene_dataset_wrappers.py\n",
            "bop_scene_dataset.py\tobject_dataset.py\t    shapenet_object_dataset.py\n",
            "datasets_cfg.py\t\tpickle_dataset.py\t    urdf_dataset.py\n",
            "deepim_modelnet.py\tpose_dataset.py\t\t    utils.py\n",
            "gso_dataset.py\t\tsamplers.py\t\t    web_scene_dataset.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/evaluation:\n",
            "bop.py\t\tevaluation.py\t      meters\t\t    utils.py\n",
            "data_utils.py\tevaluation_runner.py  prediction_runner.py\n",
            "eval_config.py\t__init__.py\t      runner_utils.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/evaluation/meters:\n",
            "base.py  __init__.py  modelnet_meters.py  utils.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/inference:\n",
            "depth_refiner.py  __init__.py\t     teaserpp_refiner.py\n",
            "detector.py\t  pose_estimator.py  types.py\n",
            "icp_refiner.py\t  refiner_utils.py   utils.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/lib3d:\n",
            "camera_geometry.py  __init__.py     rigid_mesh_database.py  transform.py\n",
            "cosypose_ops.py     mesh_losses.py  rotations.py\n",
            "cropping.py\t    mesh_ops.py     symmetries.py\n",
            "distances.py\t    multiview.py    transform_ops.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/models:\n",
            "mask_rcnn.py  pose_rigid.py  resnet.py\ttorchvision_resnet.py  wide_resnet.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/panda3d_renderer:\n",
            "geometry.py  panda3d_batch_renderer.py\ttypes.py\n",
            "__init__.py  panda3d_scene_renderer.py\tutils.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/scripts:\n",
            "distributed.py\t\t     make_shapenet_pointclouds.py\n",
            "download.py\t\t     make_shapenet_statistics.py\n",
            "generate_shapenet_pbr.py     make_shapenet_subsets.py\n",
            "__init__.py\t\t     run_full_megapose_eval.py\n",
            "make_gso_meshes.py\t     run_inference_on_example.py\n",
            "make_gso_subsets.py\t     run_megapose_training.py\n",
            "make_shapenet_panda3d.py     test_distributed.py\n",
            "make_shapenet_ply_scaled.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/tests:\n",
            "__init__.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/training:\n",
            "detector_models_cfg.py\tmegapose_forward_loss.py  training_config.py  utils.py\n",
            "__init__.py\t\tpose_models_cfg.py\t  train_megapose.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/utils:\n",
            "conversion.py\tlogging.py\t  random.py\t\ttransform_utils.py\n",
            "distributed.py\tlogs_bokeh.py\t  resources.py\t\ttypes.py\n",
            "__init__.py\tmodels_compat.py  tensor_collection.py\twebdataset.py\n",
            "load_model.py\tomegaconf.py\t  timer.py\t\txarray.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose/visualization:\n",
            "bokeh_plotter.py  __init__.py\t    meshcat_visualizer.py\n",
            "bokeh_utils.py\t  meshcat_utils.py  utils.py\n",
            "\n",
            "/content/megapose6d/megapose6d/megapose6d/src/megapose.egg-info:\n",
            "dependency_links.txt  PKG-INFO\trequires.txt  SOURCES.txt  top_level.txt\n",
            "\n",
            "/content/megapose6d/megapose6d/notebooks:\n",
            "megapose_custom_model.ipynb\t\trender_megapose_dataset.ipynb\n",
            "megapose_estimator_visualization.ipynb\n",
            "\n",
            "/content/megapose6d/megapose6d/src:\n",
            "megapose  megapose.egg-info\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose:\n",
            "bop_config.py  datasets    __init__.py\tpanda3d_renderer  training\n",
            "config.py      evaluation  lib3d\tscripts\t\t  utils\n",
            "data\t       inference   models\ttests\t\t  visualization\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/data:\n",
            "data_4608.qua  data_512.qua  data_576.qua  data_72.qua\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/datasets:\n",
            "augmentations.py\t__init__.py\t\t    scene_dataset.py\n",
            "bop_object_datasets.py\tmodelnet_object_dataset.py  scene_dataset_wrappers.py\n",
            "bop_scene_dataset.py\tobject_dataset.py\t    shapenet_object_dataset.py\n",
            "datasets_cfg.py\t\tpickle_dataset.py\t    urdf_dataset.py\n",
            "deepim_modelnet.py\tpose_dataset.py\t\t    utils.py\n",
            "gso_dataset.py\t\tsamplers.py\t\t    web_scene_dataset.py\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/evaluation:\n",
            "bop.py\t\tevaluation.py\t      meters\t\t    utils.py\n",
            "data_utils.py\tevaluation_runner.py  prediction_runner.py\n",
            "eval_config.py\t__init__.py\t      runner_utils.py\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/evaluation/meters:\n",
            "base.py  __init__.py  modelnet_meters.py  utils.py\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/inference:\n",
            "depth_refiner.py  __init__.py\t     teaserpp_refiner.py\n",
            "detector.py\t  pose_estimator.py  types.py\n",
            "icp_refiner.py\t  refiner_utils.py   utils.py\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/lib3d:\n",
            "camera_geometry.py  __init__.py     rigid_mesh_database.py  transform.py\n",
            "cosypose_ops.py     mesh_losses.py  rotations.py\n",
            "cropping.py\t    mesh_ops.py     symmetries.py\n",
            "distances.py\t    multiview.py    transform_ops.py\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/models:\n",
            "mask_rcnn.py  pose_rigid.py  resnet.py\ttorchvision_resnet.py  wide_resnet.py\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/panda3d_renderer:\n",
            "geometry.py  panda3d_batch_renderer.py\ttypes.py\n",
            "__init__.py  panda3d_scene_renderer.py\tutils.py\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/scripts:\n",
            "distributed.py\t\t     make_shapenet_pointclouds.py\n",
            "download.py\t\t     make_shapenet_statistics.py\n",
            "generate_shapenet_pbr.py     make_shapenet_subsets.py\n",
            "__init__.py\t\t     run_full_megapose_eval.py\n",
            "make_gso_meshes.py\t     run_inference_on_example.py\n",
            "make_gso_subsets.py\t     run_megapose_training.py\n",
            "make_shapenet_panda3d.py     test_distributed.py\n",
            "make_shapenet_ply_scaled.py\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/tests:\n",
            "__init__.py\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/training:\n",
            "detector_models_cfg.py\tmegapose_forward_loss.py  training_config.py  utils.py\n",
            "__init__.py\t\tpose_models_cfg.py\t  train_megapose.py\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/utils:\n",
            "conversion.py\tlogging.py\t  random.py\t\ttransform_utils.py\n",
            "distributed.py\tlogs_bokeh.py\t  resources.py\t\ttypes.py\n",
            "__init__.py\tmodels_compat.py  tensor_collection.py\twebdataset.py\n",
            "load_model.py\tomegaconf.py\t  timer.py\t\txarray.py\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose/visualization:\n",
            "bokeh_plotter.py  __init__.py\t    meshcat_visualizer.py\n",
            "bokeh_utils.py\t  meshcat_utils.py  utils.py\n",
            "\n",
            "/content/megapose6d/megapose6d/src/megapose.egg-info:\n",
            "dependency_links.txt  PKG-INFO\trequires.txt  SOURCES.txt  top_level.txt\n",
            "\n",
            "/content/megapose6d/notebooks:\n",
            "megapose_custom_model.ipynb\t\trender_megapose_dataset.ipynb\n",
            "megapose_estimator_visualization.ipynb\n",
            "\n",
            "/content/megapose6d/src:\n",
            "megapose  megapose.egg-info\n",
            "\n",
            "/content/megapose6d/src/megapose:\n",
            "bop_config.py  datasets    __init__.py\tpanda3d_renderer  training\n",
            "config.py      evaluation  lib3d\tscripts\t\t  utils\n",
            "data\t       inference   models\ttests\t\t  visualization\n",
            "\n",
            "/content/megapose6d/src/megapose/data:\n",
            "data_4608.qua  data_512.qua  data_576.qua  data_72.qua\n",
            "\n",
            "/content/megapose6d/src/megapose/datasets:\n",
            "augmentations.py\t__init__.py\t\t    scene_dataset.py\n",
            "bop_object_datasets.py\tmodelnet_object_dataset.py  scene_dataset_wrappers.py\n",
            "bop_scene_dataset.py\tobject_dataset.py\t    shapenet_object_dataset.py\n",
            "datasets_cfg.py\t\tpickle_dataset.py\t    urdf_dataset.py\n",
            "deepim_modelnet.py\tpose_dataset.py\t\t    utils.py\n",
            "gso_dataset.py\t\tsamplers.py\t\t    web_scene_dataset.py\n",
            "\n",
            "/content/megapose6d/src/megapose/evaluation:\n",
            "bop.py\t\tevaluation.py\t      meters\t\t    utils.py\n",
            "data_utils.py\tevaluation_runner.py  prediction_runner.py\n",
            "eval_config.py\t__init__.py\t      runner_utils.py\n",
            "\n",
            "/content/megapose6d/src/megapose/evaluation/meters:\n",
            "base.py  __init__.py  modelnet_meters.py  utils.py\n",
            "\n",
            "/content/megapose6d/src/megapose/inference:\n",
            "depth_refiner.py  __init__.py\t     teaserpp_refiner.py\n",
            "detector.py\t  pose_estimator.py  types.py\n",
            "icp_refiner.py\t  refiner_utils.py   utils.py\n",
            "\n",
            "/content/megapose6d/src/megapose/lib3d:\n",
            "camera_geometry.py  __init__.py     rigid_mesh_database.py  transform.py\n",
            "cosypose_ops.py     mesh_losses.py  rotations.py\n",
            "cropping.py\t    mesh_ops.py     symmetries.py\n",
            "distances.py\t    multiview.py    transform_ops.py\n",
            "\n",
            "/content/megapose6d/src/megapose/models:\n",
            "mask_rcnn.py  pose_rigid.py  resnet.py\ttorchvision_resnet.py  wide_resnet.py\n",
            "\n",
            "/content/megapose6d/src/megapose/panda3d_renderer:\n",
            "geometry.py  panda3d_batch_renderer.py\ttypes.py\n",
            "__init__.py  panda3d_scene_renderer.py\tutils.py\n",
            "\n",
            "/content/megapose6d/src/megapose/scripts:\n",
            "distributed.py\t\t     make_shapenet_pointclouds.py\n",
            "download.py\t\t     make_shapenet_statistics.py\n",
            "generate_shapenet_pbr.py     make_shapenet_subsets.py\n",
            "__init__.py\t\t     run_full_megapose_eval.py\n",
            "make_gso_meshes.py\t     run_inference_on_example.py\n",
            "make_gso_subsets.py\t     run_megapose_training.py\n",
            "make_shapenet_panda3d.py     test_distributed.py\n",
            "make_shapenet_ply_scaled.py\n",
            "\n",
            "/content/megapose6d/src/megapose/tests:\n",
            "__init__.py\n",
            "\n",
            "/content/megapose6d/src/megapose/training:\n",
            "detector_models_cfg.py\tmegapose_forward_loss.py  training_config.py  utils.py\n",
            "__init__.py\t\tpose_models_cfg.py\t  train_megapose.py\n",
            "\n",
            "/content/megapose6d/src/megapose/utils:\n",
            "conversion.py\tlogging.py\t  random.py\t\ttransform_utils.py\n",
            "distributed.py\tlogs_bokeh.py\t  resources.py\t\ttypes.py\n",
            "__init__.py\tmodels_compat.py  tensor_collection.py\twebdataset.py\n",
            "load_model.py\tomegaconf.py\t  timer.py\t\txarray.py\n",
            "\n",
            "/content/megapose6d/src/megapose/visualization:\n",
            "bokeh_plotter.py  __init__.py\t    meshcat_visualizer.py\n",
            "bokeh_utils.py\t  meshcat_utils.py  utils.py\n",
            "\n",
            "/content/megapose6d/src/megapose.egg-info:\n",
            "dependency_links.txt  PKG-INFO\trequires.txt  SOURCES.txt  top_level.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m megapose.scripts.run_inference_on_example barbecue-sauce --run-inference"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODjGSKuJ40eD",
        "outputId": "a0ee553c-42c1-4df9-a67a-6edf40bfe358"
      },
      "id": "ODjGSKuJ40eD",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MKL_NUM_THREADS: 1\n",
            "OMP_NUM_THREADS: 1\n",
            "CUDA_VISIBLE_DEVICES: 0\n",
            "EGL_VISIBLE_DEVICES: 0\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/megapose6d/megapose6d/megapose6d/megapose6d/src/megapose/scripts/run_inference_on_example.py\", line 15, in <module>\n",
            "    from megapose.config import LOCAL_DATA_DIR\n",
            "  File \"/content/megapose6d/megapose6d/megapose6d/megapose6d/src/megapose/config.py\", line 45, in <module>\n",
            "    PYTHON_BIN_PATH = Path(sys.executable)\n",
            "                           ^^^\n",
            "NameError: name 'sys' is not defined. Did you forget to import 'sys'?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d3874bde-0969-418e-9e3d-4cf9ab930413",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "d3874bde-0969-418e-9e3d-4cf9ab930413",
        "outputId": "02a7412a-46c3-4640-d44e-321e43ef5c38"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'megapose'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-499853925.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0momegaconf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOmegaConf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmegapose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmegapose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets_cfg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_scene_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'megapose'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import copy\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import transforms3d\n",
        "\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "import megapose\n",
        "\n",
        "from megapose.datasets.datasets_cfg import make_scene_dataset\n",
        "from megapose.config import LOCAL_DATA_DIR, NB_DATA_DIR\n",
        "from megapose.training.utils import RGB_DIMS\n",
        "from megapose.inference.utils import make_cameras\n",
        "import pickle as pkl\n",
        "from bokeh.io import show, output_notebook; output_notebook()\n",
        "from megapose.visualization.bokeh_plotter import BokehPlotter\n",
        "from bokeh.plotting import gridplot\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import scipy\n",
        "\n",
        "\n",
        "from megapose.training.utils import cast_images, cast_to_numpy, CudaTimer\n",
        "from megapose.lib3d.camera_geometry import get_K_crop_resize\n",
        "from megapose.datasets.scene_dataset import SceneObservation\n",
        "\n",
        "from megapose.inference.pose_estimator import PoseEstimator, ObservationTensor\n",
        "from megapose.inference.icp_refiner import ICPRefiner\n",
        "from megapose.visualization.utils import adjust_brightness, tensor_image_to_uint8, \\\n",
        "get_ds_info, make_contour_overlay\n",
        "from megapose.utils import transform_utils\n",
        "from megapose.lib3d.cosypose_ops import (\n",
        "    TCO_init_from_boxes,\n",
        "    TCO_init_from_boxes_zup_autodepth,\n",
        "    TCO_init_from_boxes_autodepth_with_R\n",
        ")\n",
        "from megapose.panda3d_renderer.types import Panda3dLightData\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "BRIGHTNESS_FACTOR=1.5\n",
        "\n",
        "# zmq_url = \"tcp://127.0.0.1:6000\"\n",
        "# zmq_url = \"tcp://127.0.0.1:6001\"\n",
        "# zmq_url = \"tcp://127.0.0.1:6004\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58da3c07",
      "metadata": {
        "id": "58da3c07"
      },
      "outputs": [],
      "source": [
        "def get_scene_data(scene_ds, scene_id, view_id):\n",
        "    df = scene_ds.frame_index\n",
        "    x = df[(df.scene_id == scene_id) & (df.view_id==view_id)]\n",
        "    ds_idx = x.iloc[0].name\n",
        "    scene_data = scene_ds[ds_idx]\n",
        "    return scene_data\n",
        "\n",
        "\n",
        "def orthogonalize_rotation(T):\n",
        "    rot = scipy.spatial.transform.Rotation.from_matrix(T[:3,:3])\n",
        "    T[:3,:3] = rot.as_matrix()\n",
        "    return T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48bbcc2a",
      "metadata": {
        "id": "48bbcc2a"
      },
      "outputs": [],
      "source": [
        "object_label = None\n",
        "\n",
        "ds_name = 'ycbv'\n",
        "scene_ds_name = f\"{ds_name}.test\"\n",
        "n_refiner_iterations = 5\n",
        "\n",
        "\n",
        "scene_id, im_idx, object_label = 54, 1, 'obj_000015' # drill\n",
        "# scene_id, im_idx, object_label = 54, 1, 'obj_000003' # sugargox\n",
        "\n",
        "\n",
        "view_id = im_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ce8f1a",
      "metadata": {
        "id": "b1ce8f1a"
      },
      "source": [
        "## Load data and visualize image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a8829f",
      "metadata": {
        "id": "b5a8829f"
      },
      "outputs": [],
      "source": [
        "# Load the images/data\n",
        "scene_ds_kwargs = {'load_depth': True}\n",
        "scene_ds = make_scene_dataset(scene_ds_name, **scene_ds_kwargs)\n",
        "scene_data = get_scene_data(scene_ds, scene_id, view_id)\n",
        "\n",
        "if scene_data.depth is not None:\n",
        "    depth = torch.as_tensor(scene_data.depth).unsqueeze(-1)\n",
        "    rgb = torch.as_tensor(scene_data.rgb)\n",
        "    image = torch.cat([rgb, depth], dim=-1).numpy()\n",
        "else:\n",
        "    image = scene_data.rgb.numpy()\n",
        "\n",
        "images = [image]\n",
        "cameras = make_cameras([scene_data.camera_data])\n",
        "\n",
        "plotter = BokehPlotter()\n",
        "image_f = plotter.plot_image(images[0][...,RGB_DIMS].astype(np.uint8))\n",
        "show(image_f)\n",
        "\n",
        "\n",
        "if object_label is None:\n",
        "    object_labels = None\n",
        "else:\n",
        "    object_labels = [object_label]\n",
        "data = SceneObservation.collate_fn([scene_data], object_labels=object_labels)\n",
        "observation_tensor = ObservationTensor.from_numpy(scene_data.rgb, depth=scene_data.depth, K=scene_data.camera_data.K)\n",
        "observation_tensor = observation_tensor.cuda()\n",
        "\n",
        "\n",
        "# Filter gt_detections to only keep the object we are interested in\n",
        "gt_detections = data['gt_detections']\n",
        "# Filter and only run the estimator for that object\n",
        "df = gt_detections.infos\n",
        "df = df[df.label == object_label]\n",
        "detection_idx = df.iloc[0].name\n",
        "gt_detections = gt_detections[[detection_idx]]\n",
        "gt_detections = gt_detections.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da56307a",
      "metadata": {
        "id": "da56307a"
      },
      "source": [
        "## Load the model\n",
        "\n",
        "Select whether to load a depth refiner or not and what type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75cc6509",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "75cc6509"
      },
      "outputs": [],
      "source": [
        "import megapose.inference.utils\n",
        "cfg = OmegaConf.create()\n",
        "cfg.model_name = 'sn-gso-4views-normals'\n",
        "cfg.ds_name = ds_name\n",
        "cfg.use_icp = False\n",
        "depth_multiplier = None\n",
        "per_iter_depth_multiplier = None\n",
        "model_data = megapose.inference.utils.load_named_model(cfg)\n",
        "result_name = cfg.model_name\n",
        "\n",
        "\n",
        "\n",
        "refiner_model = model_data['refiner_model']\n",
        "coarse_model = model_data['coarse_model']\n",
        "obj_ds_name = model_data['obj_ds_name']\n",
        "detector_model = model_data['detector_model']\n",
        "renderer = refiner_model.renderer\n",
        "\n",
        "mesh_db = refiner_model.mesh_db\n",
        "\n",
        "\n",
        "depth_refiner = None\n",
        "depth_refiner_type = None\n",
        "# depth_refiner_type = \"icp\"\n",
        "# depth_refiner_type = \"teaser++\"\n",
        "\n",
        "if depth_refiner_type == \"icp\":\n",
        "    depth_refiner = ICPRefiner(mesh_db, renderer)\n",
        "elif depth_refiner_type == \"teaserpp\":\n",
        "    from megapose.inference.teaserpp_refiner import TeaserppRefiner\n",
        "    depth_refiner = TeaserppRefiner(mesh_db, renderer)\n",
        "\n",
        "pose_estimator = PoseEstimator(refiner_model=refiner_model,\n",
        "                              coarse_model=coarse_model,\n",
        "                               detector_model=detector_model,\n",
        "                               depth_refiner=depth_refiner,\n",
        "                               bsz_objects=16,\n",
        "                               bsz_images=576,\n",
        "                              )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "297bb8d8",
      "metadata": {
        "id": "297bb8d8"
      },
      "source": [
        "## Run Model Inference\n",
        "\n",
        "- We perform the individual steps (detector, coarse, refiner, scoring) etc. separately to make the inference pipeline transparent. You can simply use pose_estimator.run_inference_pipeline to run them all at once.\n",
        "- You can set the options as to whether to use the ground-truth detections or the detections from Mask-RCNN.\n",
        "- Note: If you aren't using gt_detections and there are multiple object instances in the scene this won't work properly.\n",
        "- If you are getting CUDA out of memory errors decrease `bsz_objects` and `bsz_images` to smaller values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ec0b35",
      "metadata": {
        "id": "c3ec0b35"
      },
      "outputs": [],
      "source": [
        "# Options for inference\n",
        "use_gt_detections = True # Note, if you aren't using gt_detections then this should be false\n",
        "n_refiner_iterations = 5\n",
        "n_pose_hypotheses = 5\n",
        "return_debug_data = True\n",
        "detection_filter_kwargs = {'labels': [object_label]}\n",
        "run_depth_refiner = False\n",
        "\n",
        "\n",
        "bsz_images = 128\n",
        "bsz_objects = 2\n",
        "\n",
        "\n",
        "pose_estimator.bsz_objects = bsz_objects\n",
        "pose_estimator.bsz_images = bsz_images\n",
        "\n",
        "# set the random seed\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "\n",
        "    if use_gt_detections:\n",
        "        detections = gt_detections\n",
        "    else:\n",
        "        # Only keep the top detection in each image\n",
        "        detections = pose_estimator.forward_detection_model(observation_tensor, one_instance_per_class=True)\n",
        "\n",
        "    # Filter and only run the estimator for that object\n",
        "\n",
        "    detections = megapose.inference.utils.filter_detections(detections, **detection_filter_kwargs)\n",
        "    detections = megapose.inference.utils.add_instance_id_to_detections(detections)\n",
        "    detections = detections.cuda()\n",
        "\n",
        "\n",
        "#     print(\"detections\\n\", detections)\n",
        "\n",
        "    # We have split the inference into it's component steps for clarity. This is a copy of\n",
        "    # what is in the pose_estimator.run_pipeline method\n",
        "    # Run the coarse estimator using gt_detections\n",
        "    data_TCO_coarse, extra_data = pose_estimator.forward_coarse_model(observation=observation_tensor,\n",
        "                                       detections=detections, cuda_timer=True)\n",
        "\n",
        "    print(f\"Forward Coarse: total={extra_data['time']:.2f}, \"\\\n",
        "          f\"model_time={extra_data['model_time']:.2f}, render_time={extra_data['render_time']:.2f}\")\n",
        "\n",
        "    # Extract top-K coarse hypotheses\n",
        "    data_TCO_filtered = pose_estimator.filter_pose_estimates(data_TCO_coarse,\n",
        "                                                             top_K=n_pose_hypotheses,\n",
        "                                                             filter_field='coarse_logit')\n",
        "\n",
        "    # Refine the top_K coarse hypotheses\n",
        "    preds, extra_data = pose_estimator.forward_refiner(observation_tensor, data_TCO_filtered,\n",
        "                                                   n_iterations=n_refiner_iterations, keep_all_outputs=True)\n",
        "\n",
        "    print(f\"Refiner time: {extra_data['time']:.2f}\")\n",
        "    data_TCO_refined = preds[f'iteration={n_refiner_iterations}']\n",
        "    refiner_preds = preds\n",
        "    refiner_outputs = extra_data['outputs']\n",
        "\n",
        "    # Score the refined poses using the coarse model.\n",
        "    data_TCO_scored, extra_data = pose_estimator.forward_scoring_model(observation_tensor, data_TCO_refined)\n",
        "\n",
        "    # Extract the highest scoring pose estimate for each instance_id\n",
        "    data_TCO_final = pose_estimator.filter_pose_estimates(data_TCO_scored, top_K=1, filter_field='pose_logit')\n",
        "\n",
        "\n",
        "    if run_depth_refiner:\n",
        "        print(\"\\n\\n\")\n",
        "        t = time.time()\n",
        "        data_TCO_depth_refiner, _ = pose_estimator.run_depth_refiner(observation_tensor, data_TCO_final,\n",
        "                                                                    )\n",
        "        depth_refiner_time = time.time() - t\n",
        "    else:\n",
        "        data_TCO_depth_refiner = None\n",
        "\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"Entire pose estimation pipeline took {elapsed:.2f} seconds\")\n",
        "\n",
        "print(\"Final Pose Estimate\\n\")\n",
        "print(data_TCO_final)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2061433",
      "metadata": {
        "id": "c2061433"
      },
      "source": [
        "## Run the entire pipeline\n",
        "\n",
        "- The cell below shows how to run the entire pipeline in one function call, rather than each step individually.\n",
        "- It is disabled by default, set the flag to `True` to run the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "664f8ceb",
      "metadata": {
        "id": "664f8ceb"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    use_gt_detections = False\n",
        "    if use_gt_detections:\n",
        "        detections_in = gt_detections.cuda()\n",
        "        run_detector=False\n",
        "    else:\n",
        "        detections_in = None\n",
        "        run_detector=True\n",
        "\n",
        "\n",
        "    detection_filter_kwargs = {'labels': [object_label], 'one_instance_per_class':True}\n",
        "\n",
        "    data_TCO_out, pred_data = pose_estimator.run_inference_pipeline(observation_tensor,\n",
        "                                         detections=detections_in,\n",
        "                                         run_detector=run_detector,\n",
        "                                         n_refiner_iterations=5,\n",
        "                                         n_pose_hypotheses=5,\n",
        "                                        detection_filter_kwargs=detection_filter_kwargs,\n",
        "                                        cuda_timer=True)\n",
        "\n",
        "    print(f\"Inference pipeline: {pred_data['timing_str']}\")\n",
        "    print(f\"Coarse model: {pred_data['coarse']['data']['timing_str']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3039fcdc",
      "metadata": {
        "id": "3039fcdc"
      },
      "source": [
        "## Extract data from refiner iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "001c05de",
      "metadata": {
        "tags": [],
        "id": "001c05de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "bda6ccf3-b97a-4fb1-df79-979377b3af95"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'n_refiner_iterations' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4187263554.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mplot_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mplot_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_refiner_iterations\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;31m# plot_iter = [1,2,3,4,5,6,7,8]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mall_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'n_refiner_iterations' is not defined"
          ]
        }
      ],
      "source": [
        "def plot_cosypose(data, data_TCO_final, refiner_outputs_in, object_label,\n",
        "                  plot_iter=[1, 2, 3, 4], scene_data=None):\n",
        "#     orig_renderer = object_predictor.pose_predictor.refiner_model.renderer\n",
        "#     object_predictor.pose_predictor.refiner_model.renderer = renderer\n",
        "\n",
        "    rows = []\n",
        "    outputs = []\n",
        "\n",
        "    df = data_TCO_final.infos\n",
        "    df_filter = df[df.label == object_label]\n",
        "    assert len(df_filter) == 1, f\"There was more than one object named {object_label} in refiner_preds\"\n",
        "\n",
        "    refiner_batch_idx = df_filter.iloc[0]['refiner_batch_idx']\n",
        "    refiner_instance_idx = df_filter.iloc[0][\"refiner_instance_idx\"]\n",
        "\n",
        "\n",
        "    df_gt = data['gt_detections'].infos\n",
        "    df_gt_filter = df_gt[df_gt.label == object_label]\n",
        "\n",
        "    assert len(df_gt_filter) == 1, f\"There was more than one object named {object_label} in data['gt_detections']\"\n",
        "    obj_idx_gt = df_gt_filter.iloc[0].name\n",
        "    TWC = scene_data.camera_data.TWC.matrix\n",
        "    TCO_gt = data['gt_detections'].poses[obj_idx_gt].cpu().numpy().astype(np.float64)\n",
        "    TOC_gt = np.linalg.inv(TCO_gt)\n",
        "\n",
        "\n",
        "    if 'data_TCO_init' in all_preds:\n",
        "        data_TCO_init = all_preds['data_TCO_init']\n",
        "        df = data_TCO_init.infos\n",
        "        df = df[df.label == object_label]\n",
        "        idx_tmp = df.index[0]\n",
        "        TCO_coarse_init = cast_to_numpy(data_TCO_init.poses[idx_tmp], np.float64)\n",
        "    else:\n",
        "        TCO_coarse_init = None\n",
        "\n",
        "\n",
        "\n",
        "    for n in plot_iter:\n",
        "        refiner_outputs_iter = refiner_outputs_in[refiner_batch_idx][f'iteration={n}']\n",
        "        image_crop = refiner_outputs[refiner_batch_idx][f'iteration={n}']['images_crop']\\\n",
        "            [refiner_instance_idx][RGB_DIMS]\n",
        "        render_crop = refiner_outputs[refiner_batch_idx][f'iteration={n}']['renders']\\\n",
        "            [refiner_instance_idx][RGB_DIMS]\n",
        "\n",
        "        image_crop = (image_crop.permute(1, 2, 0) * 255).cpu().numpy().astype(np.uint8)\n",
        "        render_crop = (render_crop.permute(1, 2, 0) * 255).cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        image_f = plotter.plot_image(image_crop)\n",
        "        render_f = plotter.plot_image(render_crop)\n",
        "        overlay_f = plotter.plot_overlay(image_crop, render_crop)\n",
        "        row = [image_f, render_f, overlay_f]\n",
        "        TCO_pred = refiner_outputs[refiner_batch_idx][f'iteration={n}']['TCO_input'][refiner_instance_idx].cpu().numpy()\n",
        "        TCO_output = refiner_outputs[refiner_batch_idx][f'iteration={n}']['TCO_input'][refiner_instance_idx].cpu().numpy()\n",
        "\n",
        "\n",
        "        # compute errors\n",
        "        TCO_pred = orthogonalize_rotation(TCO_pred)\n",
        "        TOgt_O = np.linalg.inv(TCO_gt) @ TCO_pred\n",
        "        TOgt_O = orthogonalize_rotation(TOgt_O)\n",
        "        trans_err = np.linalg.norm(TOgt_O[:3,3])\n",
        "\n",
        "\n",
        "        # Compute coarse score\n",
        "        rgb = data['rgb']\n",
        "        depth = data['depth']\n",
        "\n",
        "        # [B,C,H,W], C=3 or 4 depending on if depth was empty or not\n",
        "        # Compute score from coarse model\n",
        "        images = cast_images_to_tensor(rgb, depth)\n",
        "        K = data['cameras'].K.cuda().float()\n",
        "        label = [object_label]\n",
        "        TCO_pred_tensor = torch.tensor(TCO_pred).cuda().unsqueeze(0)\n",
        "        out_ = coarse_model.forward_coarse(images, K, label, TCO_input=TCO_pred_tensor,\n",
        "                                           return_debug_data=True)\n",
        "\n",
        "        coarse_out = out_\n",
        "\n",
        "\n",
        "        try:\n",
        "            _, rot_err_angle_radians = transforms3d.axangles.mat2axangle(TOgt_O[:3,:3])\n",
        "            rot_err_deg = np.rad2deg(np.abs(rot_err_angle_radians))\n",
        "        except ValueError:\n",
        "            print(\"got error while computing angle distance\")\n",
        "            rot_err_deg = -1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        infos = dict(figures=row,\n",
        "                     TCO_output=TCO_output,\n",
        "                     TCO_input=TCO_pred,\n",
        "                     TCO_gt=TCO_gt,\n",
        "                     TOC_gt=TOC_gt,\n",
        "                     TOgt_O=TOgt_O,\n",
        "                     label=object_label,\n",
        "                     refiner_batch_idx=refiner_batch_idx,\n",
        "                     refiner_instance_idx=refiner_instance_idx,\n",
        "                     iteration=n,\n",
        "                     refiner_outputs=refiner_outputs_iter,\n",
        "                     scene_data=scene_data,\n",
        "                     input_rgb_dims=copy.copy(refiner_model.input_rgb_dims),\n",
        "                     input_depth_dims=copy.copy(refiner_model.input_depth_dims),\n",
        "                     render_rgb_dims=copy.copy(refiner_model.render_rgb_dims),\n",
        "                     render_depth_dims=copy.copy(refiner_model.render_depth_dims),\n",
        "                     TCO_coarse_init=TCO_coarse_init,\n",
        "                     trans_err=trans_err,\n",
        "                     rot_err=rot_err_deg,\n",
        "                     coarse_out=coarse_out,\n",
        "#                      TCO_coarse_init=TCO_coarse_init,\n",
        "#                      object_predictor_data=object_predictor_data,\n",
        "                    )\n",
        "        outputs.append(infos)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plot_iter = [1, 2, 3,4,5,6]\n",
        "plot_iter = list(range(1, n_refiner_iterations+1))\n",
        "# plot_iter = [1,2,3,4,5,6,7,8]\n",
        "all_preds = preds\n",
        "all_infos = plot_cosypose(data, data_TCO_final, refiner_outputs,\n",
        "                          object_label, plot_iter, scene_data=scene_data)\n",
        "\n",
        "for info in all_infos:\n",
        "    info['result_name'] = result_name\n",
        "all_infos = pd.DataFrame(all_infos)\n",
        "\n",
        "# save_path = NB_DATA_DIR / f'{result_name}_ds_name={ds_name}_scene_id={scene_id}_im={view_id}_object_label={object_label}.pkl'\n",
        "# save_path.write_bytes(pkl.dumps(all_infos.drop(columns=('figures'))))\n",
        "# print(\"wrote\", save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b69819c",
      "metadata": {
        "id": "3b69819c"
      },
      "source": [
        "## Make contour overlay figure\n",
        "\n",
        "Overlay ground-truth and estimated pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "19771898",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "19771898",
        "outputId": "bad7d86b-65f5-43dd-96fb-8f4a314e4f42"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'NB_DATA_DIR' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-897449611.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSAVE_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNB_DATA_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'figures'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mambient_light_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPanda3dLightData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ambient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NB_DATA_DIR' is not defined"
          ]
        }
      ],
      "source": [
        "SAVE_DIR = NB_DATA_DIR/'figures'\n",
        "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "ambient_light_data = Panda3dLightData('ambient')\n",
        "light_datas = [[ambient_light_data]]\n",
        "\n",
        "\n",
        "# Need to render an image at the ground-truth pose\n",
        "d = dict()\n",
        "for n in [n_refiner_iterations]:\n",
        "\n",
        "    # Initial coarse estimate\n",
        "    x = refiner_outputs[0][f'iteration={n}']\n",
        "    render_img_tensor = x['renders'][0,0:3]\n",
        "    render_img = tensor_image_to_uint8(render_img_tensor)\n",
        "    render_img_PIL = Image.fromarray(render_img)\n",
        "    render_img_PIL = adjust_brightness(render_img_PIL, factor=BRIGHTNESS_FACTOR)\n",
        "    render_img_PIL.save(f'{SAVE_DIR}/refiner_iter={n}_render.png')\n",
        "\n",
        "\n",
        "    img_tensor = x['images_crop'][0, 0:3]\n",
        "    img = tensor_image_to_uint8(img_tensor)\n",
        "    img_PIL = Image.fromarray(img)\n",
        "\n",
        "    img_PIL.save(SAVE_DIR/f\"refiner_iter={n}_img_crop.png\")\n",
        "\n",
        "    blend = BokehPlotter.make_overlay(img, np.array(render_img_PIL))\n",
        "\n",
        "    contour_out = make_contour_overlay(img, np.array(render_img_PIL), dilate_iterations=1, color=[0,255,0])\n",
        "    contour = contour_out['img']\n",
        "\n",
        "    contour_both = make_contour_overlay(img, np.array(render_img_PIL), color=[255,0,0],\n",
        "                                       dilate_iterations=0)['img']\n",
        "\n",
        "\n",
        "    ### Render image at the ground-truth pose #######\n",
        "    # [1,3,3]\n",
        "    pred_idx = 0\n",
        "    K = x['K_crop'][pred_idx].unsqueeze(0)\n",
        "\n",
        "    df = all_infos\n",
        "    df = df[df.iteration==n]\n",
        "\n",
        "    # [1,4,4]\n",
        "    TCO_gt = torch.tensor(df.iloc[0].TCO_gt).unsqueeze(0)\n",
        "\n",
        "\n",
        "#     if n > 1:\n",
        "#         print(\"TCO:\\n\", x['TCO_input'])\n",
        "#         print(\"TCO_gt:\\n\", TCO_gt)\n",
        "\n",
        "#     TCO_gt = x['TCO_output'][pred_idx].unsqueeze(0)\n",
        "    obj_infos = [{'name': x['labels'][pred_idx]}]\n",
        "#     print(\"obj_infos\", obj_infos)\n",
        "\n",
        "\n",
        "\n",
        "    render_out = renderer.render(labels=[object_label],\n",
        "                                 TCO=TCO_gt,\n",
        "                                 K=K,\n",
        "                                 resolution=img.shape[:2],\n",
        "                                 light_datas=light_datas)\n",
        "\n",
        "\n",
        "    render_img_gt_tensor = render_out.rgbs[0]\n",
        "    render_img_gt = tensor_image_to_uint8(render_img_gt_tensor)\n",
        "\n",
        "    render_img_gt_PIL = Image.fromarray(render_img_gt)\n",
        "    render_img_gt_PIL = adjust_brightness(render_img_gt_PIL, factor=BRIGHTNESS_FACTOR)\n",
        "    render_img_gt_PIL.save(f'{SAVE_DIR}/refiner_iter={n}_render_gt_pose.png')\n",
        "\n",
        "\n",
        "    contour_both = make_contour_overlay(contour_both, np.array(render_img_gt_PIL), color=[0,255,0],\n",
        "                                       dilate_iterations=0)['img']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    contour_both_PIL = Image.fromarray(contour_both)\n",
        "    contour_both_PIL.save(f'{SAVE_DIR}/refiner_iter={n}_contour_both.png')\n",
        "\n",
        "\n",
        "    if data_TCO_depth_refiner is not None:\n",
        "        df = data_TCO_depth_refiner.infos\n",
        "        df = df[df.label == object_label]\n",
        "        assert len(df) == 1, f\"Found more than one prediction with label {object_label}\"\n",
        "        TCO = data_TCO_depth_refiner.poses[df.index.tolist()]\n",
        "        render_out = renderer.render(labels=[object_label],\n",
        "                                 TCO=TCO,\n",
        "                                 K=K,\n",
        "                                 resolution=img.shape[:2],\n",
        "                                 light_datas=light_datas)\n",
        "        render_img_depth_refiner_tensor = render_out.rgbs[0]\n",
        "        render_img_depth_refiner = tensor_image_to_uint8(render_img_gt_tensor)\n",
        "        contour_depth_refiner = make_contour_overlay(img, render_img_depth_refiner, dilate_iterations=1, color=[0,255,0])\n",
        "\n",
        "    else:\n",
        "        contour_depth_refiner = None\n",
        "\n",
        "\n",
        "\n",
        "    d[n] = {'render': np.array(render_img_PIL),\n",
        "           'img': img,\n",
        "           'blend': blend,\n",
        "           'contour': contour,\n",
        "           'contour_out': contour_out,\n",
        "           'render_gt': np.array(render_img_gt_PIL),\n",
        "           'contour_both': np.array(contour_both_PIL),\n",
        "            'contour_depth_refiner': contour_depth_refiner,\n",
        "           }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(d[n_refiner_iterations]['img'])\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(d[n_refiner_iterations]['render'])\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(d[n_refiner_iterations]['contour_out']['img'])\n",
        "plt.title(\"Megapose Refiner\")\n",
        "plt.show()\n",
        "\n",
        "if d[n_refiner_iterations]['contour_depth_refiner'] is not None:\n",
        "    plt.figure()\n",
        "    plt.imshow(d[n_refiner_iterations]['contour_depth_refiner']['img'])\n",
        "    plt.title(\"Megapose + Depth refiner\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d367460",
      "metadata": {
        "id": "7d367460"
      },
      "source": [
        "## Visualize refiner iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "058eb3ae",
      "metadata": {
        "id": "058eb3ae"
      },
      "outputs": [],
      "source": [
        "print(f\"scene_id: {scene_id}, view_id: {im_idx}, object_label: {object_label}\")\n",
        "grid = []\n",
        "# plot_iter = [1,2,3,4,5,6,7,8]\n",
        "plot_object_label = [object_label]\n",
        "df = all_infos.copy()\n",
        "df = df.loc[(df['iteration'].isin(plot_iter)) & (df['label'] == object_label)]\n",
        "for _, row in df.iterrows():\n",
        "    figures = row['figures']\n",
        "    result_name = row['result_name']\n",
        "    logit = float(row['coarse_out']['logits'][0])\n",
        "    score = float(row['coarse_out']['scores'][0])\n",
        "    k = row['iteration']\n",
        "    figures[1].title.text = f'{result_name} / iter={k} / logit={logit:.1f}, score={score:.1f} '\n",
        "    figures[2].title.text_font_size = '12pt'\n",
        "    grid.append(figures)\n",
        "show(gridplot(grid, sizing_mode='scale_width'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "820b9200",
      "metadata": {
        "id": "820b9200"
      },
      "source": [
        "## 3D visualization using meshcat.\n",
        "\n",
        "Make sure you have a `meshcat-server` process running on the host machine. Otherwise this code will hang."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ccdae7d",
      "metadata": {
        "id": "8ccdae7d"
      },
      "outputs": [],
      "source": [
        "from megapose.visualization import meshcat_utils\n",
        "from megapose.visualization.meshcat_visualizer import MeshcatSceneViewer\n",
        "import meshcat.geometry as g\n",
        "vis = meshcat_utils.create_visualizer()\n",
        "\n",
        "df = all_infos\n",
        "show_iter = [n_refiner_iterations]\n",
        "df = df.loc[(df['iteration'].isin(show_iter))]\n",
        "\n",
        "viewer = MeshcatSceneViewer(obj_ds_name, use_textures=True,)\n",
        "# viewer = MeshcatSceneViewer('ycbv', use_textures=False) # debugging\n",
        "vis = viewer.visualizer\n",
        "\n",
        "def extract_pointcloud_from_scene_data(scene_data):\n",
        "    depth = scene_data.depth\n",
        "    K = scene_data.camera_data.K\n",
        "    pc = meshcat_utils.get_pointcloud(depth, K)\n",
        "\n",
        "    return pc\n",
        "\n",
        "\n",
        "def extract_pointclouds(iter_info):\n",
        "    refiner_outputs = iter_info['refiner_outputs']\n",
        "    unique_id = iter_info['refiner_instance_idx']\n",
        "    image_crop_raw = refiner_outputs['images_crop_raw'][unique_id]\n",
        "    render_raw = refiner_outputs['renders_raw'][unique_id]\n",
        "    K_crop = refiner_outputs['K_crop'][unique_id].cpu().numpy()\n",
        "    KV_crop = refiner_outputs['KV_crop'][unique_id][0].cpu().numpy()\n",
        "    TCO_input = refiner_outputs['TCO_input'][unique_id].cpu().numpy()\n",
        "\n",
        "    input_depth_dims = iter_info['input_depth_dims']\n",
        "    render_depth_dims = iter_info['render_depth_dims']\n",
        "    if len(input_depth_dims) > 0:\n",
        "        input_depth = image_crop_raw[input_depth_dims].permute(1,2,0).cpu().squeeze().numpy()\n",
        "        gt_pc = meshcat_utils.get_pointcloud(input_depth, K_crop)\n",
        "    else:\n",
        "        gt_pc = None\n",
        "\n",
        "\n",
        "    if len(render_depth_dims) > 0:\n",
        "        render_depth = render_raw[render_depth_dims].permute(1,2,0).cpu().squeeze().numpy()\n",
        "        render_pc = meshcat_utils.get_pointcloud(render_depth, KV_crop)\n",
        "    else:\n",
        "        render_pc = None\n",
        "\n",
        "\n",
        "    return {'gt': gt_pc,\n",
        "           'render': render_pc,\n",
        "            'TCO_input': TCO_input,\n",
        "           }\n",
        "\n",
        "def plot_results(df):\n",
        "    df = df.to_dict('records')\n",
        "\n",
        "    obj_infos = []\n",
        "    TCO_gt = df[0]['TCO_gt']\n",
        "    TOC_gt = np.linalg.inv(TCO_gt)\n",
        "    obj_label = df[0]['label']\n",
        "    # Visualize camera\n",
        "\n",
        "    for row in df:\n",
        "        meshcat_prefix = f\"{row['result_name']}\"\n",
        "        TOgt_O = np.linalg.inv(TCO_gt) @ row['TCO_input']\n",
        "        k = f\"{row['result_name']}/iteration={row['iteration']}/mesh\"\n",
        "        obj_infos.append({'name': obj_label, 'TWO': TOgt_O, 'node_name': k})\n",
        "\n",
        "\n",
        "    if data_TCO_depth_refiner is not None:\n",
        "        df_ = data_TCO_depth_refiner.infos\n",
        "        idx = df_[df_.label == object_label].iloc[0].name\n",
        "        TCO_depth_refiner = data_TCO_depth_refiner.poses[idx].cpu().numpy()\n",
        "        TOgt_O = np.linalg.inv(TCO_gt) @ TCO_depth_refiner\n",
        "        k = f\"{row['result_name']}/depth_refiner/mesh\"\n",
        "        obj_infos.append({'name': obj_label, 'TWO': TOgt_O, 'node_name': k})\n",
        "\n",
        "\n",
        "#     if 'TCO_coarse_init' in df[0]:\n",
        "#         TCO_coarse_init = cast_to_numpy(df[0]['TCO_coarse_init'], np.float64)\n",
        "#         TOgt_O = TOC_gt @ TCO_coarse_init\n",
        "#         obj_infos.append({'name': obj_label, 'TWO': TOgt_O, 'node_name': f'{meshcat_prefix}/TCO_coarse_init/mesh'})\n",
        "\n",
        "\n",
        "    obj_infos.append({'name': obj_label, 'TWO': np.eye(4), 'node_name': 'ground_truth'})\n",
        "    viewer.visualize_scene(obj_infos)\n",
        "\n",
        "    # Extra visualization must be after the 'visualize_scene' call\n",
        "    meshcat_utils.make_frame(vis, \"camera\", transform=TOC_gt, ignore_invalid_transform=True)\n",
        "\n",
        "    # Line connecting camera and origin\n",
        "    vertices = np.zeros([3,2])\n",
        "    vertices[:, 1] = TOC_gt[:3,3]\n",
        "    vis['line'].set_object(g.Line(g.PointsGeometry(vertices)))\n",
        "\n",
        "\n",
        "    # visualize ground-truth pointcloud\n",
        "    pc_gt = extract_pointcloud_from_scene_data(df[0]['scene_data'])\n",
        "    meshcat_utils.visualize_pointcloud(vis, 'ground_truth_pointcloud', pc_gt, transform=TOC_gt,\n",
        "                                              color=[0,255,0])\n",
        "\n",
        "\n",
        "    # visualize depth images, but only for final index\n",
        "    for row in df:\n",
        "        pc_data = extract_pointclouds(row)\n",
        "        f\"{row['result_name']}/iteration={row['iteration']}\"\n",
        "#         if pc_data['gt'] is not None:\n",
        "#             print(\"Visualizing ground-truth pointcloud\")\n",
        "#             meshcat_utils.visualize_pointcloud(vis, 'ground_truth_pointcloud', pc_data['gt'], transform=TOC_gt,\n",
        "#                                               color=[0,255,0])\n",
        "\n",
        "        if pc_data['render'] is not None:\n",
        "            TOgt_O = np.linalg.inv(TCO_gt) @ row['TCO_input']\n",
        "            TCO_input = pc_data['TCO_input']\n",
        "            TOC_input = np.linalg.inv(TCO_input)\n",
        "            TOgt_input = TOgt_O @ TOC_input # transform rendered to observed\n",
        "\n",
        "            k = f\"{row['result_name']}/iteration={row['iteration']}/pointcloud\"\n",
        "            meshcat_utils.visualize_pointcloud(vis, k, pc_data['render'],\n",
        "                                               transform=TOC_gt, color=[255,255,0])\n",
        "\n",
        "    return\n",
        "\n",
        "plot_results(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d79c7aa",
      "metadata": {
        "id": "5d79c7aa"
      },
      "source": [
        "## Print accuracy data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eccf3e9",
      "metadata": {
        "id": "8eccf3e9"
      },
      "outputs": [],
      "source": [
        "df = all_infos\n",
        "df_first_iter = df[df.iteration==1]\n",
        "trans_err_init = float(df_first_iter.trans_err)\n",
        "rot_err_init = float(df_first_iter.rot_err)\n",
        "last_iter = df.iteration.max()\n",
        "# print(\"last_iter\", last_iter)\n",
        "df_final_iter = df[df.iteration==df.iteration.max()]\n",
        "\n",
        "trans_err = float(df_final_iter.trans_err)\n",
        "rot_err = float(df_final_iter.rot_err)\n",
        "# print(df_final_iter.tran)\n",
        "# df_final_iter = df_final_iter.iloc[0]\n",
        "\n",
        "SO3_grid_size = pose_estimator._SO3_grid.shape[0]\n",
        "# print(x_failure)\n",
        "print(f\"result_name: {result_name}, SO3-grid-size={SO3_grid_size}\")\n",
        "print(f\"iteration={last_iter}\")\n",
        "print(f\"per_iter_depth_multiplier:\", refiner_model.per_iter_depth_multiplier)\n",
        "print(\"depth_multiplier:\", refiner_model.depth_multiplier)\n",
        "print(f\"\\ninitial translation error (cm): {trans_err_init*100:.2f}\")\n",
        "print(f\"initial rot_err (no sym) (deg): {rot_err_init:.1f}\")\n",
        "print(f\"\\ntranslation error (cm): {trans_err*100:.2f}\\nrot_err (no sym) (deg): {rot_err:.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f7f8e12",
      "metadata": {
        "id": "9f7f8e12"
      },
      "source": [
        "#####\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab857fc",
      "metadata": {
        "id": "7ab857fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e22c6f",
      "metadata": {
        "id": "b9e22c6f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}