{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install conda\n",
        "\n",
        "git clone https://github.com/megapose6d/megapose6d.git\n",
        "cd megapose6d && git submodule update --init\n",
        "\n",
        "conda env create -f conda/environment_full.yaml\n",
        "conda activate megapose\n",
        "pip install -e .\n",
        "\n",
        "python -m megapose.scripts.download --megapose_models\n",
        "python -m megapose.scripts.download --example_data\n",
        "python -m megapose.scripts.run_inference_on_example barbecue-sauce --vis-detections"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "NMbsScTG9QoL",
        "outputId": "527384ff-f7bb-41c8-e5fe-42aac82ca149"
      },
      "id": "NMbsScTG9QoL",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-2484226016.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2484226016.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install conda\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2413a4e0",
        "outputId": "314ea64d-d256-4f5a-deb2-84e490d1255a"
      },
      "source": [
        "# Install Miniconda\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "!bash ./miniconda.sh -b -p /opt/conda\n",
        "!rm miniconda.sh\n",
        "\n",
        "# Add conda to PATH\n",
        "import sys\n",
        "sys.path.append('/opt/conda/bin')"
      ],
      "id": "2413a4e0",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-27 23:24:01--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:bf9e, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 156323998 (149M) [application/octet-stream]\n",
            "Saving to: ‘miniconda.sh’\n",
            "\n",
            "miniconda.sh        100%[===================>] 149.08M   114MB/s    in 1.3s    \n",
            "\n",
            "2025-10-27 23:24:02 (114 MB/s) - ‘miniconda.sh’ saved [156323998/156323998]\n",
            "\n",
            "PREFIX=/opt/conda\n",
            "Unpacking bootstrapper...\n",
            "Unpacking payload...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /opt/conda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2736c636",
        "outputId": "1a09a9fb-cf59-4d88-82bf-7cf65d1bac2c"
      },
      "source": [
        "# Check if the directory exists and remove it if it does\n",
        "import os\n",
        "if os.path.exists('megapose6d'):\n",
        "    !rm -rf megapose6d\n",
        "\n",
        "!git clone https://github.com/megapose6d/megapose6d.git\n",
        "%cd megapose6d && git submodule update --init"
      ],
      "id": "2736c636",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'megapose6d'...\n",
            "remote: Enumerating objects: 205, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 205 (delta 23), reused 14 (delta 14), pack-reused 146 (from 2)\u001b[K\n",
            "Receiving objects: 100% (205/205), 19.55 MiB | 21.32 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n",
            "[Errno 2] No such file or directory: 'megapose6d && git submodule update --init'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf8fe6c8",
        "outputId": "a6b0b28d-b3b2-4355-ea2a-9ca2a172c10a"
      },
      "source": [
        "# Ensure conda is in the PATH by initializing it in the shell\n",
        "!source /opt/conda/etc/profile.d/conda.sh && conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
        "!source /opt/conda/etc/profile.d/conda.sh && conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
        "!source /opt/conda/etc/profile.d/conda.sh && conda env create -f /content/megapose6d/conda/environment_full.yaml\n",
        "!source /opt/conda/etc/profile.d/conda.sh && cd /content/megapose6d && conda activate megapose && pip install -e ."
      ],
      "id": "bf8fe6c8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accepted Terms of Service for \u001b[4;94mhttps://repo.anaconda.com/pkgs/main\u001b[0m\n",
            "accepted Terms of Service for \u001b[4;94mhttps://repo.anaconda.com/pkgs/r\u001b[0m\n",
            "\u001b[1;33mJupyter detected\u001b[0m\u001b[1;33m...\u001b[0m\n",
            "\u001b[1;32m2\u001b[0m\u001b[1;32m channel Terms of Service accepted\u001b[0m\n",
            "Retrieving notices: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Channels:\n",
            " - conda-forge\n",
            " - pytorch\n",
            " - anaconda\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d48ffab",
        "outputId": "317e2eba-f0fc-403c-db5c-b38faa1d9c1c"
      },
      "source": [
        "# Ensure conda is in the PATH and activate the environment before running commands\n",
        "# Navigate to the megapose6d directory before running the scripts\n",
        "!source /opt/conda/etc/profile.d/conda.sh && cd /content/megapose6d && conda activate megapose && python -m megapose.scripts.download --megapose_models\n",
        "!source /opt/conda/etc/profile.d/conda.sh && cd /content/megapose6d && conda activate megapose && python -m megapose.scripts.download --example_data\n",
        "!source /opt/conda/etc/profile.d/conda.sh && cd /content/megapose6d && conda activate megapose && python -m megapose.scripts.run_inference_on_example barbecue-sauce --vis-detections"
      ],
      "id": "4d48ffab",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'megapose.scripts.download' (ModuleNotFoundError: No module named 'megapose')\n",
            "/usr/bin/python3: Error while finding module specification for 'megapose.scripts.download' (ModuleNotFoundError: No module named 'megapose')\n",
            "/usr/bin/python3: Error while finding module specification for 'megapose.scripts.run_inference_on_example' (ModuleNotFoundError: No module named 'megapose')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d3874bde-0969-418e-9e3d-4cf9ab930413",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "d3874bde-0969-418e-9e3d-4cf9ab930413",
        "outputId": "f6e75ce8-8fdc-4910-a4c9-bd64b44ca035"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'imp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1248137179.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-57>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/extensions/autoreload.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msource_from_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m#------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "import copy\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import transforms3d\n",
        "\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "import megapose\n",
        "\n",
        "from megapose.datasets.datasets_cfg import make_scene_dataset\n",
        "from megapose.config import LOCAL_DATA_DIR, NB_DATA_DIR\n",
        "from megapose.training.utils import RGB_DIMS\n",
        "from megapose.inference.utils import make_cameras\n",
        "import pickle as pkl\n",
        "from bokeh.io import show, output_notebook; output_notebook()\n",
        "from megapose.visualization.bokeh_plotter import BokehPlotter\n",
        "from bokeh.plotting import gridplot\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import scipy\n",
        "\n",
        "\n",
        "from megapose.training.utils import cast_images, cast_to_numpy, CudaTimer\n",
        "from megapose.lib3d.camera_geometry import get_K_crop_resize\n",
        "from megapose.datasets.scene_dataset import SceneObservation\n",
        "\n",
        "from megapose.inference.pose_estimator import PoseEstimator, ObservationTensor\n",
        "from megapose.inference.icp_refiner import ICPRefiner\n",
        "from megapose.visualization.utils import adjust_brightness, tensor_image_to_uint8, \\\n",
        "get_ds_info, make_contour_overlay\n",
        "from megapose.utils import transform_utils\n",
        "from megapose.lib3d.cosypose_ops import (\n",
        "    TCO_init_from_boxes,\n",
        "    TCO_init_from_boxes_zup_autodepth,\n",
        "    TCO_init_from_boxes_autodepth_with_R\n",
        ")\n",
        "from megapose.panda3d_renderer.types import Panda3dLightData\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "BRIGHTNESS_FACTOR=1.5\n",
        "\n",
        "# zmq_url = \"tcp://127.0.0.1:6000\"\n",
        "# zmq_url = \"tcp://127.0.0.1:6001\"\n",
        "# zmq_url = \"tcp://127.0.0.1:6004\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58da3c07",
      "metadata": {
        "id": "58da3c07"
      },
      "outputs": [],
      "source": [
        "def get_scene_data(scene_ds, scene_id, view_id):\n",
        "    df = scene_ds.frame_index\n",
        "    x = df[(df.scene_id == scene_id) & (df.view_id==view_id)]\n",
        "    ds_idx = x.iloc[0].name\n",
        "    scene_data = scene_ds[ds_idx]\n",
        "    return scene_data\n",
        "\n",
        "\n",
        "def orthogonalize_rotation(T):\n",
        "    rot = scipy.spatial.transform.Rotation.from_matrix(T[:3,:3])\n",
        "    T[:3,:3] = rot.as_matrix()\n",
        "    return T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48bbcc2a",
      "metadata": {
        "id": "48bbcc2a"
      },
      "outputs": [],
      "source": [
        "object_label = None\n",
        "\n",
        "ds_name = 'ycbv'\n",
        "scene_ds_name = f\"{ds_name}.test\"\n",
        "n_refiner_iterations = 5\n",
        "\n",
        "\n",
        "scene_id, im_idx, object_label = 54, 1, 'obj_000015' # drill\n",
        "# scene_id, im_idx, object_label = 54, 1, 'obj_000003' # sugargox\n",
        "\n",
        "\n",
        "view_id = im_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ce8f1a",
      "metadata": {
        "id": "b1ce8f1a"
      },
      "source": [
        "## Load data and visualize image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a8829f",
      "metadata": {
        "id": "b5a8829f"
      },
      "outputs": [],
      "source": [
        "# Load the images/data\n",
        "scene_ds_kwargs = {'load_depth': True}\n",
        "scene_ds = make_scene_dataset(scene_ds_name, **scene_ds_kwargs)\n",
        "scene_data = get_scene_data(scene_ds, scene_id, view_id)\n",
        "\n",
        "if scene_data.depth is not None:\n",
        "    depth = torch.as_tensor(scene_data.depth).unsqueeze(-1)\n",
        "    rgb = torch.as_tensor(scene_data.rgb)\n",
        "    image = torch.cat([rgb, depth], dim=-1).numpy()\n",
        "else:\n",
        "    image = scene_data.rgb.numpy()\n",
        "\n",
        "images = [image]\n",
        "cameras = make_cameras([scene_data.camera_data])\n",
        "\n",
        "plotter = BokehPlotter()\n",
        "image_f = plotter.plot_image(images[0][...,RGB_DIMS].astype(np.uint8))\n",
        "show(image_f)\n",
        "\n",
        "\n",
        "if object_label is None:\n",
        "    object_labels = None\n",
        "else:\n",
        "    object_labels = [object_label]\n",
        "data = SceneObservation.collate_fn([scene_data], object_labels=object_labels)\n",
        "observation_tensor = ObservationTensor.from_numpy(scene_data.rgb, depth=scene_data.depth, K=scene_data.camera_data.K)\n",
        "observation_tensor = observation_tensor.cuda()\n",
        "\n",
        "\n",
        "# Filter gt_detections to only keep the object we are interested in\n",
        "gt_detections = data['gt_detections']\n",
        "# Filter and only run the estimator for that object\n",
        "df = gt_detections.infos\n",
        "df = df[df.label == object_label]\n",
        "detection_idx = df.iloc[0].name\n",
        "gt_detections = gt_detections[[detection_idx]]\n",
        "gt_detections = gt_detections.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da56307a",
      "metadata": {
        "id": "da56307a"
      },
      "source": [
        "## Load the model\n",
        "\n",
        "Select whether to load a depth refiner or not and what type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75cc6509",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "75cc6509"
      },
      "outputs": [],
      "source": [
        "import megapose.inference.utils\n",
        "cfg = OmegaConf.create()\n",
        "cfg.model_name = 'sn-gso-4views-normals'\n",
        "cfg.ds_name = ds_name\n",
        "cfg.use_icp = False\n",
        "depth_multiplier = None\n",
        "per_iter_depth_multiplier = None\n",
        "model_data = megapose.inference.utils.load_named_model(cfg)\n",
        "result_name = cfg.model_name\n",
        "\n",
        "\n",
        "\n",
        "refiner_model = model_data['refiner_model']\n",
        "coarse_model = model_data['coarse_model']\n",
        "obj_ds_name = model_data['obj_ds_name']\n",
        "detector_model = model_data['detector_model']\n",
        "renderer = refiner_model.renderer\n",
        "\n",
        "mesh_db = refiner_model.mesh_db\n",
        "\n",
        "\n",
        "depth_refiner = None\n",
        "depth_refiner_type = None\n",
        "# depth_refiner_type = \"icp\"\n",
        "# depth_refiner_type = \"teaser++\"\n",
        "\n",
        "if depth_refiner_type == \"icp\":\n",
        "    depth_refiner = ICPRefiner(mesh_db, renderer)\n",
        "elif depth_refiner_type == \"teaserpp\":\n",
        "    from megapose.inference.teaserpp_refiner import TeaserppRefiner\n",
        "    depth_refiner = TeaserppRefiner(mesh_db, renderer)\n",
        "\n",
        "pose_estimator = PoseEstimator(refiner_model=refiner_model,\n",
        "                              coarse_model=coarse_model,\n",
        "                               detector_model=detector_model,\n",
        "                               depth_refiner=depth_refiner,\n",
        "                               bsz_objects=16,\n",
        "                               bsz_images=576,\n",
        "                              )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "297bb8d8",
      "metadata": {
        "id": "297bb8d8"
      },
      "source": [
        "## Run Model Inference\n",
        "\n",
        "- We perform the individual steps (detector, coarse, refiner, scoring) etc. separately to make the inference pipeline transparent. You can simply use pose_estimator.run_inference_pipeline to run them all at once.\n",
        "- You can set the options as to whether to use the ground-truth detections or the detections from Mask-RCNN.\n",
        "- Note: If you aren't using gt_detections and there are multiple object instances in the scene this won't work properly.\n",
        "- If you are getting CUDA out of memory errors decrease `bsz_objects` and `bsz_images` to smaller values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ec0b35",
      "metadata": {
        "id": "c3ec0b35"
      },
      "outputs": [],
      "source": [
        "# Options for inference\n",
        "use_gt_detections = True # Note, if you aren't using gt_detections then this should be false\n",
        "n_refiner_iterations = 5\n",
        "n_pose_hypotheses = 5\n",
        "return_debug_data = True\n",
        "detection_filter_kwargs = {'labels': [object_label]}\n",
        "run_depth_refiner = False\n",
        "\n",
        "\n",
        "bsz_images = 128\n",
        "bsz_objects = 2\n",
        "\n",
        "\n",
        "pose_estimator.bsz_objects = bsz_objects\n",
        "pose_estimator.bsz_images = bsz_images\n",
        "\n",
        "# set the random seed\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "\n",
        "    if use_gt_detections:\n",
        "        detections = gt_detections\n",
        "    else:\n",
        "        # Only keep the top detection in each image\n",
        "        detections = pose_estimator.forward_detection_model(observation_tensor, one_instance_per_class=True)\n",
        "\n",
        "    # Filter and only run the estimator for that object\n",
        "\n",
        "    detections = megapose.inference.utils.filter_detections(detections, **detection_filter_kwargs)\n",
        "    detections = megapose.inference.utils.add_instance_id_to_detections(detections)\n",
        "    detections = detections.cuda()\n",
        "\n",
        "\n",
        "#     print(\"detections\\n\", detections)\n",
        "\n",
        "    # We have split the inference into it's component steps for clarity. This is a copy of\n",
        "    # what is in the pose_estimator.run_pipeline method\n",
        "    # Run the coarse estimator using gt_detections\n",
        "    data_TCO_coarse, extra_data = pose_estimator.forward_coarse_model(observation=observation_tensor,\n",
        "                                       detections=detections, cuda_timer=True)\n",
        "\n",
        "    print(f\"Forward Coarse: total={extra_data['time']:.2f}, \"\\\n",
        "          f\"model_time={extra_data['model_time']:.2f}, render_time={extra_data['render_time']:.2f}\")\n",
        "\n",
        "    # Extract top-K coarse hypotheses\n",
        "    data_TCO_filtered = pose_estimator.filter_pose_estimates(data_TCO_coarse,\n",
        "                                                             top_K=n_pose_hypotheses,\n",
        "                                                             filter_field='coarse_logit')\n",
        "\n",
        "    # Refine the top_K coarse hypotheses\n",
        "    preds, extra_data = pose_estimator.forward_refiner(observation_tensor, data_TCO_filtered,\n",
        "                                                   n_iterations=n_refiner_iterations, keep_all_outputs=True)\n",
        "\n",
        "    print(f\"Refiner time: {extra_data['time']:.2f}\")\n",
        "    data_TCO_refined = preds[f'iteration={n_refiner_iterations}']\n",
        "    refiner_preds = preds\n",
        "    refiner_outputs = extra_data['outputs']\n",
        "\n",
        "    # Score the refined poses using the coarse model.\n",
        "    data_TCO_scored, extra_data = pose_estimator.forward_scoring_model(observation_tensor, data_TCO_refined)\n",
        "\n",
        "    # Extract the highest scoring pose estimate for each instance_id\n",
        "    data_TCO_final = pose_estimator.filter_pose_estimates(data_TCO_scored, top_K=1, filter_field='pose_logit')\n",
        "\n",
        "\n",
        "    if run_depth_refiner:\n",
        "        print(\"\\n\\n\")\n",
        "        t = time.time()\n",
        "        data_TCO_depth_refiner, _ = pose_estimator.run_depth_refiner(observation_tensor, data_TCO_final,\n",
        "                                                                    )\n",
        "        depth_refiner_time = time.time() - t\n",
        "    else:\n",
        "        data_TCO_depth_refiner = None\n",
        "\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"Entire pose estimation pipeline took {elapsed:.2f} seconds\")\n",
        "\n",
        "print(\"Final Pose Estimate\\n\")\n",
        "print(data_TCO_final)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2061433",
      "metadata": {
        "id": "c2061433"
      },
      "source": [
        "## Run the entire pipeline\n",
        "\n",
        "- The cell below shows how to run the entire pipeline in one function call, rather than each step individually.\n",
        "- It is disabled by default, set the flag to `True` to run the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "664f8ceb",
      "metadata": {
        "id": "664f8ceb"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    use_gt_detections = False\n",
        "    if use_gt_detections:\n",
        "        detections_in = gt_detections.cuda()\n",
        "        run_detector=False\n",
        "    else:\n",
        "        detections_in = None\n",
        "        run_detector=True\n",
        "\n",
        "\n",
        "    detection_filter_kwargs = {'labels': [object_label], 'one_instance_per_class':True}\n",
        "\n",
        "    data_TCO_out, pred_data = pose_estimator.run_inference_pipeline(observation_tensor,\n",
        "                                         detections=detections_in,\n",
        "                                         run_detector=run_detector,\n",
        "                                         n_refiner_iterations=5,\n",
        "                                         n_pose_hypotheses=5,\n",
        "                                        detection_filter_kwargs=detection_filter_kwargs,\n",
        "                                        cuda_timer=True)\n",
        "\n",
        "    print(f\"Inference pipeline: {pred_data['timing_str']}\")\n",
        "    print(f\"Coarse model: {pred_data['coarse']['data']['timing_str']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3039fcdc",
      "metadata": {
        "id": "3039fcdc"
      },
      "source": [
        "## Extract data from refiner iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "001c05de",
      "metadata": {
        "tags": [],
        "id": "001c05de"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_cosypose(data, data_TCO_final, refiner_outputs_in, object_label,\n",
        "                  plot_iter=[1, 2, 3, 4], scene_data=None):\n",
        "#     orig_renderer = object_predictor.pose_predictor.refiner_model.renderer\n",
        "#     object_predictor.pose_predictor.refiner_model.renderer = renderer\n",
        "\n",
        "    rows = []\n",
        "    outputs = []\n",
        "\n",
        "    df = data_TCO_final.infos\n",
        "    df_filter = df[df.label == object_label]\n",
        "    assert len(df_filter) == 1, f\"There was more than one object named {object_label} in refiner_preds\"\n",
        "\n",
        "    refiner_batch_idx = df_filter.iloc[0]['refiner_batch_idx']\n",
        "    refiner_instance_idx = df_filter.iloc[0][\"refiner_instance_idx\"]\n",
        "\n",
        "\n",
        "    df_gt = data['gt_detections'].infos\n",
        "    df_gt_filter = df_gt[df_gt.label == object_label]\n",
        "\n",
        "    assert len(df_gt_filter) == 1, f\"There was more than one object named {object_label} in data['gt_detections']\"\n",
        "    obj_idx_gt = df_gt_filter.iloc[0].name\n",
        "    TWC = scene_data.camera_data.TWC.matrix\n",
        "    TCO_gt = data['gt_detections'].poses[obj_idx_gt].cpu().numpy().astype(np.float64)\n",
        "    TOC_gt = np.linalg.inv(TCO_gt)\n",
        "\n",
        "\n",
        "    if 'data_TCO_init' in all_preds:\n",
        "        data_TCO_init = all_preds['data_TCO_init']\n",
        "        df = data_TCO_init.infos\n",
        "        df = df[df.label == object_label]\n",
        "        idx_tmp = df.index[0]\n",
        "        TCO_coarse_init = cast_to_numpy(data_TCO_init.poses[idx_tmp], np.float64)\n",
        "    else:\n",
        "        TCO_coarse_init = None\n",
        "\n",
        "\n",
        "\n",
        "    for n in plot_iter:\n",
        "        refiner_outputs_iter = refiner_outputs_in[refiner_batch_idx][f'iteration={n}']\n",
        "        image_crop = refiner_outputs[refiner_batch_idx][f'iteration={n}']['images_crop']\\\n",
        "            [refiner_instance_idx][RGB_DIMS]\n",
        "        render_crop = refiner_outputs[refiner_batch_idx][f'iteration={n}']['renders']\\\n",
        "            [refiner_instance_idx][RGB_DIMS]\n",
        "\n",
        "        image_crop = (image_crop.permute(1, 2, 0) * 255).cpu().numpy().astype(np.uint8)\n",
        "        render_crop = (render_crop.permute(1, 2, 0) * 255).cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        image_f = plotter.plot_image(image_crop)\n",
        "        render_f = plotter.plot_image(render_crop)\n",
        "        overlay_f = plotter.plot_overlay(image_crop, render_crop)\n",
        "        row = [image_f, render_f, overlay_f]\n",
        "        TCO_pred = refiner_outputs[refiner_batch_idx][f'iteration={n}']['TCO_input'][refiner_instance_idx].cpu().numpy()\n",
        "        TCO_output = refiner_outputs[refiner_batch_idx][f'iteration={n}']['TCO_input'][refiner_instance_idx].cpu().numpy()\n",
        "\n",
        "\n",
        "        # compute errors\n",
        "        TCO_pred = orthogonalize_rotation(TCO_pred)\n",
        "        TOgt_O = np.linalg.inv(TCO_gt) @ TCO_pred\n",
        "        TOgt_O = orthogonalize_rotation(TOgt_O)\n",
        "        trans_err = np.linalg.norm(TOgt_O[:3,3])\n",
        "\n",
        "\n",
        "        # Compute coarse score\n",
        "        rgb = data['rgb']\n",
        "        depth = data['depth']\n",
        "\n",
        "        # [B,C,H,W], C=3 or 4 depending on if depth was empty or not\n",
        "        # Compute score from coarse model\n",
        "        images = cast_images_to_tensor(rgb, depth)\n",
        "        K = data['cameras'].K.cuda().float()\n",
        "        label = [object_label]\n",
        "        TCO_pred_tensor = torch.tensor(TCO_pred).cuda().unsqueeze(0)\n",
        "        out_ = coarse_model.forward_coarse(images, K, label, TCO_input=TCO_pred_tensor,\n",
        "                                           return_debug_data=True)\n",
        "\n",
        "        coarse_out = out_\n",
        "\n",
        "\n",
        "        try:\n",
        "            _, rot_err_angle_radians = transforms3d.axangles.mat2axangle(TOgt_O[:3,:3])\n",
        "            rot_err_deg = np.rad2deg(np.abs(rot_err_angle_radians))\n",
        "        except ValueError:\n",
        "            print(\"got error while computing angle distance\")\n",
        "            rot_err_deg = -1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        infos = dict(figures=row,\n",
        "                     TCO_output=TCO_output,\n",
        "                     TCO_input=TCO_pred,\n",
        "                     TCO_gt=TCO_gt,\n",
        "                     TOC_gt=TOC_gt,\n",
        "                     TOgt_O=TOgt_O,\n",
        "                     label=object_label,\n",
        "                     refiner_batch_idx=refiner_batch_idx,\n",
        "                     refiner_instance_idx=refiner_instance_idx,\n",
        "                     iteration=n,\n",
        "                     refiner_outputs=refiner_outputs_iter,\n",
        "                     scene_data=scene_data,\n",
        "                     input_rgb_dims=copy.copy(refiner_model.input_rgb_dims),\n",
        "                     input_depth_dims=copy.copy(refiner_model.input_depth_dims),\n",
        "                     render_rgb_dims=copy.copy(refiner_model.render_rgb_dims),\n",
        "                     render_depth_dims=copy.copy(refiner_model.render_depth_dims),\n",
        "                     TCO_coarse_init=TCO_coarse_init,\n",
        "                     trans_err=trans_err,\n",
        "                     rot_err=rot_err_deg,\n",
        "                     coarse_out=coarse_out,\n",
        "#                      TCO_coarse_init=TCO_coarse_init,\n",
        "#                      object_predictor_data=object_predictor_data,\n",
        "                    )\n",
        "        outputs.append(infos)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plot_iter = [1, 2, 3,4,5,6]\n",
        "plot_iter = list(range(1, n_refiner_iterations+1))\n",
        "# plot_iter = [1,2,3,4,5,6,7,8]\n",
        "all_preds = preds\n",
        "all_infos = plot_cosypose(data, data_TCO_final, refiner_outputs,\n",
        "                          object_label, plot_iter, scene_data=scene_data)\n",
        "\n",
        "for info in all_infos:\n",
        "    info['result_name'] = result_name\n",
        "all_infos = pd.DataFrame(all_infos)\n",
        "\n",
        "# save_path = NB_DATA_DIR / f'{result_name}_ds_name={ds_name}_scene_id={scene_id}_im={view_id}_object_label={object_label}.pkl'\n",
        "# save_path.write_bytes(pkl.dumps(all_infos.drop(columns=('figures'))))\n",
        "# print(\"wrote\", save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b69819c",
      "metadata": {
        "id": "3b69819c"
      },
      "source": [
        "## Make contour overlay figure\n",
        "\n",
        "Overlay ground-truth and estimated pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "19771898",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "19771898",
        "outputId": "9d2fa365-ee08-4b01-d159-525593304ae8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'NB_DATA_DIR' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2168680895.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSAVE_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNB_DATA_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'figures'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mambient_light_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPanda3dLightData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ambient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NB_DATA_DIR' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "SAVE_DIR = NB_DATA_DIR/'figures'\n",
        "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "ambient_light_data = Panda3dLightData('ambient')\n",
        "light_datas = [[ambient_light_data]]\n",
        "\n",
        "\n",
        "# Need to render an image at the ground-truth pose\n",
        "d = dict()\n",
        "for n in [n_refiner_iterations]:\n",
        "\n",
        "    # Initial coarse estimate\n",
        "    x = refiner_outputs[0][f'iteration={n}']\n",
        "    render_img_tensor = x['renders'][0,0:3]\n",
        "    render_img = tensor_image_to_uint8(render_img_tensor)\n",
        "    render_img_PIL = Image.fromarray(render_img)\n",
        "    render_img_PIL = adjust_brightness(render_img_PIL, factor=BRIGHTNESS_FACTOR)\n",
        "    render_img_PIL.save(f'{SAVE_DIR}/refiner_iter={n}_render.png')\n",
        "\n",
        "\n",
        "    img_tensor = x['images_crop'][0, 0:3]\n",
        "    img = tensor_image_to_uint8(img_tensor)\n",
        "    img_PIL = Image.fromarray(img)\n",
        "\n",
        "    img_PIL.save(SAVE_DIR/f\"refiner_iter={n}_img_crop.png\")\n",
        "\n",
        "    blend = Plotter.make_overlay(img, np.array(render_img_PIL))\n",
        "\n",
        "    contour_out = make_contour_overlay(img, np.array(render_img_PIL), dilate_iterations=1, color=[0,255,0])\n",
        "    contour = contour_out['img']\n",
        "\n",
        "    contour_both = make_contour_overlay(img, np.array(render_img_PIL), color=[255,0,0],\n",
        "                                       dilate_iterations=0)['img']\n",
        "\n",
        "\n",
        "    ### Render image at the ground-truth pose #######\n",
        "    # [1,3,3]\n",
        "    pred_idx = 0\n",
        "    K = x['K_crop'][pred_idx].unsqueeze(0)\n",
        "\n",
        "    df = all_infos\n",
        "    df = df[df.iteration==n]\n",
        "\n",
        "    # [1,4,4]\n",
        "    TCO_gt = torch.tensor(df.iloc[0].TCO_gt).unsqueeze(0)\n",
        "\n",
        "\n",
        "#     if n > 1:\n",
        "#         print(\"TCO:\\n\", x['TCO_input'])\n",
        "#         print(\"TCO_gt:\\n\", TCO_gt)\n",
        "\n",
        "#     TCO_gt = x['TCO_output'][pred_idx].unsqueeze(0)\n",
        "    obj_infos = [{'name': x['labels'][pred_idx]}]\n",
        "#     print(\"obj_infos\", obj_infos)\n",
        "\n",
        "\n",
        "\n",
        "    render_out = renderer.render(labels=[object_label],\n",
        "                                 TCO=TCO_gt,\n",
        "                                 K=K,\n",
        "                                 resolution=img.shape[:2],\n",
        "                                 light_datas=light_datas)\n",
        "\n",
        "\n",
        "    render_img_gt_tensor = render_out.rgbs[0]\n",
        "    render_img_gt = tensor_image_to_uint8(render_img_gt_tensor)\n",
        "\n",
        "    render_img_gt_PIL = Image.fromarray(render_img_gt)\n",
        "    render_img_gt_PIL = adjust_brightness(render_img_gt_PIL, factor=BRIGHTNESS_FACTOR)\n",
        "    render_img_gt_PIL.save(f'{SAVE_DIR}/refiner_iter={n}_render_gt_pose.png')\n",
        "\n",
        "\n",
        "    contour_both = make_contour_overlay(contour_both, np.array(render_img_gt_PIL), color=[0,255,0],\n",
        "                                       dilate_iterations=0)['img']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    contour_both_PIL = Image.fromarray(contour_both)\n",
        "    contour_both_PIL.save(f'{SAVE_DIR}/refiner_iter={n}_contour_both.png')\n",
        "\n",
        "\n",
        "    if data_TCO_depth_refiner is not None:\n",
        "        df = data_TCO_depth_refiner.infos\n",
        "        df = df[df.label == object_label]\n",
        "        assert len(df) == 1, f\"Found more than one prediction with label {object_label}\"\n",
        "        TCO = data_TCO_depth_refiner.poses[df.index.tolist()]\n",
        "        render_out = renderer.render(labels=[object_label],\n",
        "                                 TCO=TCO,\n",
        "                                 K=K,\n",
        "                                 resolution=img.shape[:2],\n",
        "                                 light_datas=light_datas)\n",
        "        render_img_depth_refiner_tensor = render_out.rgbs[0]\n",
        "        render_img_depth_refiner = tensor_image_to_uint8(render_img_gt_tensor)\n",
        "        contour_depth_refiner = make_contour_overlay(img, render_img_depth_refiner, dilate_iterations=1, color=[0,255,0])\n",
        "\n",
        "    else:\n",
        "        contour_depth_refiner = None\n",
        "\n",
        "\n",
        "\n",
        "    d[n] = {'render': np.array(render_img_PIL),\n",
        "           'img': img,\n",
        "           'blend': blend,\n",
        "           'contour': contour,\n",
        "           'contour_out': contour_out,\n",
        "           'render_gt': np.array(render_img_gt_PIL),\n",
        "           'contour_both': np.array(contour_both_PIL),\n",
        "            'contour_depth_refiner': contour_depth_refiner,\n",
        "           }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(d[n_refiner_iterations]['img'])\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(d[n_refiner_iterations]['render'])\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(d[n_refiner_iterations]['contour_out']['img'])\n",
        "plt.title(\"Megapose Refiner\")\n",
        "plt.show()\n",
        "\n",
        "if d[n_refiner_iterations]['contour_depth_refiner'] is not None:\n",
        "    plt.figure()\n",
        "    plt.imshow(d[n_refiner_iterations]['contour_depth_refiner']['img'])\n",
        "    plt.title(\"Megapose + Depth refiner\")\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d367460",
      "metadata": {
        "id": "7d367460"
      },
      "source": [
        "## Visualize refiner iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "058eb3ae",
      "metadata": {
        "id": "058eb3ae"
      },
      "outputs": [],
      "source": [
        "print(f\"scene_id: {scene_id}, view_id: {im_idx}, object_label: {object_label}\")\n",
        "grid = []\n",
        "# plot_iter = [1,2,3,4,5,6,7,8]\n",
        "plot_object_label = [object_label]\n",
        "df = all_infos.copy()\n",
        "df = df.loc[(df['iteration'].isin(plot_iter)) & (df['label'] == object_label)]\n",
        "for _, row in df.iterrows():\n",
        "    figures = row['figures']\n",
        "    result_name = row['result_name']\n",
        "    logit = float(row['coarse_out']['logits'][0])\n",
        "    score = float(row['coarse_out']['scores'][0])\n",
        "    k = row['iteration']\n",
        "    figures[1].title.text = f'{result_name} / iter={k} / logit={logit:.1f}, score={score:.1f} '\n",
        "    figures[2].title.text_font_size = '12pt'\n",
        "    grid.append(figures)\n",
        "show(gridplot(grid, sizing_mode='scale_width'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "820b9200",
      "metadata": {
        "id": "820b9200"
      },
      "source": [
        "## 3D visualization using meshcat.\n",
        "\n",
        "Make sure you have a `meshcat-server` process running on the host machine. Otherwise this code will hang."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ccdae7d",
      "metadata": {
        "id": "8ccdae7d"
      },
      "outputs": [],
      "source": [
        "from megapose.visualization import meshcat_utils\n",
        "from megapose.visualization.meshcat_visualizer import MeshcatSceneViewer\n",
        "import meshcat.geometry as g\n",
        "vis = meshcat_utils.create_visualizer()\n",
        "\n",
        "df = all_infos\n",
        "show_iter = [n_refiner_iterations]\n",
        "df = df.loc[(df['iteration'].isin(show_iter))]\n",
        "\n",
        "viewer = MeshcatSceneViewer(obj_ds_name, use_textures=True,)\n",
        "# viewer = MeshcatSceneViewer('ycbv', use_textures=False) # debugging\n",
        "vis = viewer.visualizer\n",
        "\n",
        "def extract_pointcloud_from_scene_data(scene_data):\n",
        "    depth = scene_data.depth\n",
        "    K = scene_data.camera_data.K\n",
        "    pc = meshcat_utils.get_pointcloud(depth, K)\n",
        "\n",
        "    return pc\n",
        "\n",
        "\n",
        "def extract_pointclouds(iter_info):\n",
        "    refiner_outputs = iter_info['refiner_outputs']\n",
        "    unique_id = iter_info['refiner_instance_idx']\n",
        "    image_crop_raw = refiner_outputs['images_crop_raw'][unique_id]\n",
        "    render_raw = refiner_outputs['renders_raw'][unique_id]\n",
        "    K_crop = refiner_outputs['K_crop'][unique_id].cpu().numpy()\n",
        "    KV_crop = refiner_outputs['KV_crop'][unique_id][0].cpu().numpy()\n",
        "    TCO_input = refiner_outputs['TCO_input'][unique_id].cpu().numpy()\n",
        "\n",
        "    input_depth_dims = iter_info['input_depth_dims']\n",
        "    render_depth_dims = iter_info['render_depth_dims']\n",
        "    if len(input_depth_dims) > 0:\n",
        "        input_depth = image_crop_raw[input_depth_dims].permute(1,2,0).cpu().squeeze().numpy()\n",
        "        gt_pc = meshcat_utils.get_pointcloud(input_depth, K_crop)\n",
        "    else:\n",
        "        gt_pc = None\n",
        "\n",
        "\n",
        "    if len(render_depth_dims) > 0:\n",
        "        render_depth = render_raw[render_depth_dims].permute(1,2,0).cpu().squeeze().numpy()\n",
        "        render_pc = meshcat_utils.get_pointcloud(render_depth, KV_crop)\n",
        "    else:\n",
        "        render_pc = None\n",
        "\n",
        "\n",
        "    return {'gt': gt_pc,\n",
        "           'render': render_pc,\n",
        "            'TCO_input': TCO_input,\n",
        "           }\n",
        "\n",
        "def plot_results(df):\n",
        "    df = df.to_dict('records')\n",
        "\n",
        "    obj_infos = []\n",
        "    TCO_gt = df[0]['TCO_gt']\n",
        "    TOC_gt = np.linalg.inv(TCO_gt)\n",
        "    obj_label = df[0]['label']\n",
        "    # Visualize camera\n",
        "\n",
        "    for row in df:\n",
        "        meshcat_prefix = f\"{row['result_name']}\"\n",
        "        TOgt_O = np.linalg.inv(TCO_gt) @ row['TCO_input']\n",
        "        k = f\"{row['result_name']}/iteration={row['iteration']}/mesh\"\n",
        "        obj_infos.append({'name': obj_label, 'TWO': TOgt_O, 'node_name': k})\n",
        "\n",
        "\n",
        "    if data_TCO_depth_refiner is not None:\n",
        "        df_ = data_TCO_depth_refiner.infos\n",
        "        idx = df_[df_.label == object_label].iloc[0].name\n",
        "        TCO_depth_refiner = data_TCO_depth_refiner.poses[idx].cpu().numpy()\n",
        "        TOgt_O = np.linalg.inv(TCO_gt) @ TCO_depth_refiner\n",
        "        k = f\"{row['result_name']}/depth_refiner/mesh\"\n",
        "        obj_infos.append({'name': obj_label, 'TWO': TOgt_O, 'node_name': k})\n",
        "\n",
        "\n",
        "#     if 'TCO_coarse_init' in df[0]:\n",
        "#         TCO_coarse_init = cast_to_numpy(df[0]['TCO_coarse_init'], np.float64)\n",
        "#         TOgt_O = TOC_gt @ TCO_coarse_init\n",
        "#         obj_infos.append({'name': obj_label, 'TWO': TOgt_O, 'node_name': f'{meshcat_prefix}/TCO_coarse_init/mesh'})\n",
        "\n",
        "\n",
        "    obj_infos.append({'name': obj_label, 'TWO': np.eye(4), 'node_name': 'ground_truth'})\n",
        "    viewer.visualize_scene(obj_infos)\n",
        "\n",
        "    # Extra visualization must be after the 'visualize_scene' call\n",
        "    meshcat_utils.make_frame(vis, \"camera\", transform=TOC_gt, ignore_invalid_transform=True)\n",
        "\n",
        "    # Line connecting camera and origin\n",
        "    vertices = np.zeros([3,2])\n",
        "    vertices[:, 1] = TOC_gt[:3,3]\n",
        "    vis['line'].set_object(g.Line(g.PointsGeometry(vertices)))\n",
        "\n",
        "\n",
        "    # visualize ground-truth pointcloud\n",
        "    pc_gt = extract_pointcloud_from_scene_data(df[0]['scene_data'])\n",
        "    meshcat_utils.visualize_pointcloud(vis, 'ground_truth_pointcloud', pc_gt, transform=TOC_gt,\n",
        "                                              color=[0,255,0])\n",
        "\n",
        "\n",
        "    # visualize depth images, but only for final index\n",
        "    for row in df:\n",
        "        pc_data = extract_pointclouds(row)\n",
        "        f\"{row['result_name']}/iteration={row['iteration']}\"\n",
        "#         if pc_data['gt'] is not None:\n",
        "#             print(\"Visualizing ground-truth pointcloud\")\n",
        "#             meshcat_utils.visualize_pointcloud(vis, 'ground_truth_pointcloud', pc_data['gt'], transform=TOC_gt,\n",
        "#                                               color=[0,255,0])\n",
        "\n",
        "        if pc_data['render'] is not None:\n",
        "            TOgt_O = np.linalg.inv(TCO_gt) @ row['TCO_input']\n",
        "            TCO_input = pc_data['TCO_input']\n",
        "            TOC_input = np.linalg.inv(TCO_input)\n",
        "            TOgt_input = TOgt_O @ TOC_input # transform rendered to observed\n",
        "\n",
        "            k = f\"{row['result_name']}/iteration={row['iteration']}/pointcloud\"\n",
        "            meshcat_utils.visualize_pointcloud(vis, k, pc_data['render'],\n",
        "                                               transform=TOC_gt, color=[255,255,0])\n",
        "\n",
        "    return\n",
        "\n",
        "plot_results(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d79c7aa",
      "metadata": {
        "id": "5d79c7aa"
      },
      "source": [
        "## Print accuracy data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eccf3e9",
      "metadata": {
        "id": "8eccf3e9"
      },
      "outputs": [],
      "source": [
        "df = all_infos\n",
        "df_first_iter = df[df.iteration==1]\n",
        "trans_err_init = float(df_first_iter.trans_err)\n",
        "rot_err_init = float(df_first_iter.rot_err)\n",
        "last_iter = df.iteration.max()\n",
        "# print(\"last_iter\", last_iter)\n",
        "df_final_iter = df[df.iteration==df.iteration.max()]\n",
        "\n",
        "trans_err = float(df_final_iter.trans_err)\n",
        "rot_err = float(df_final_iter.rot_err)\n",
        "# print(df_final_iter.tran)\n",
        "# df_final_iter = df_final_iter.iloc[0]\n",
        "\n",
        "SO3_grid_size = pose_estimator._SO3_grid.shape[0]\n",
        "# print(x_failure)\n",
        "print(f\"result_name: {result_name}, SO3-grid-size={SO3_grid_size}\")\n",
        "print(f\"iteration={last_iter}\")\n",
        "print(f\"per_iter_depth_multiplier:\", refiner_model.per_iter_depth_multiplier)\n",
        "print(\"depth_multiplier:\", refiner_model.depth_multiplier)\n",
        "print(f\"\\ninitial translation error (cm): {trans_err_init*100:.2f}\")\n",
        "print(f\"initial rot_err (no sym) (deg): {rot_err_init:.1f}\")\n",
        "print(f\"\\ntranslation error (cm): {trans_err*100:.2f}\\nrot_err (no sym) (deg): {rot_err:.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f7f8e12",
      "metadata": {
        "id": "9f7f8e12"
      },
      "source": [
        "#####\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab857fc",
      "metadata": {
        "id": "7ab857fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e22c6f",
      "metadata": {
        "id": "b9e22c6f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}